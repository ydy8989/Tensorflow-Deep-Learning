{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorpack tutorial \n",
    "#### In this tutorial, we are going to cover following steps.\n",
    "* **Data Loading** (Dataflow)\n",
    "* **Build a model**\n",
    "* **Training & test** (CPU, GPU, or MultiGPU)\n",
    "* **Trasfer learning** (Loading a saved Model and training it agiain)\n",
    "* **Evaluation** (Loading a saved Model and test it)\n",
    "\n",
    "#### You can find more detailed descriptions by function in [here](https://tensorpack.readthedocs.io/modules/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2           # for AugmentImageComponent\n",
    "import multiprocessing\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from tensorpack import *\n",
    "from tensorpack.dataflow import *\n",
    "from tensorpack.tfutils import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get DataFlow\n",
    "* You can **augment** your data in here.\n",
    "* `Keywords`: **dataflow**, **imgaug**, **AugmentImageComponent**, **BatchData**, **PrefetchDataZMQ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dataflow(batch_size, is_train='train'):\n",
    "    df = dataset.Mnist(is_train, shuffle=True)\n",
    "    istrain = is_train == 'train'\n",
    "    \n",
    "    # ----- Image Augmentation Options -------- #\n",
    "    if istrain:\n",
    "        augs = [\n",
    "            #   imgaug.CenterCrop(256, 256),\n",
    "            #   imgaug.Resize((225, 225)),\n",
    "            #   imgaug.Grayscale(keepdims=True),\n",
    "            #   imgaug.Flip(horiz=True, vert=False, prob=0.5),\n",
    "        ]\n",
    "    else:\n",
    "        augs = [\n",
    "            #   imgaug.CenterCrop(256, 256),\n",
    "            #   imgaug.Resize((225, 225)),\n",
    "        ]\n",
    "    df = AugmentImageComponent(df, augs)\n",
    "    # group data into batches of size 128\n",
    "    df = BatchData(df, batch_size)\n",
    "    # start 3 processes to run the dataflow in parallel\n",
    "    # df = PrefetchDataZMQ(df, 10, multiprocessing.cpu_count())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0815 23:16:53 @fs.py:100]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Env var $TENSORPACK_DATASET not set, using /Users/chayesol/tensorpack_data for datasets.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABkAAAAF2CAYAAAA2iFSZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<Figure size 2016x2016 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = get_dataflow(4, 'train')\n",
    "df.reset_state()\n",
    "\n",
    "fig =plt.figure(figsize=(28, 28))\n",
    "\n",
    "for idx, dp in enumerate(df.get_data()):\n",
    "    if idx == 0:\n",
    "        for i in range(4):\n",
    "            img = dp[idx][i]\n",
    "            fig.add_subplot(1, 4, i + 1)\n",
    "            plt.imshow(img, cmap='gray')\n",
    "        plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model \n",
    "#### Model includes Loss function & Optimizer\n",
    "* Description of ModelDesc at [here]( https://tensorpack.readthedocs.io/modules/graph_builder.html#tensorpack.graph_builder.ModelDesc).\n",
    "* `Keywords`: **ModelDesc**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model(ModelDesc):\n",
    "    \n",
    "    def inputs(self):\n",
    "        \"\"\"\n",
    "        Define input shape\n",
    "        \"\"\"\n",
    "        return [tf.placeholder(tf.float32, [None, 28, 28], 'input'),\n",
    "                tf.placeholder(tf.int32, [None], 'label')]\n",
    "\n",
    "    def build_graph(self, image, label):\n",
    "        \"\"\"\n",
    "        Build the model which takes the input and return cost. \n",
    "        \"\"\"\n",
    "        # NHW to NHWC\n",
    "        image = tf.expand_dims(image, 3)\n",
    "\n",
    "        with argscope(Conv2D, kernel_size=3, activation=tf.nn.relu):\n",
    "            with tf.name_scope('layer') as scope:\n",
    "                logits = (LinearWrap(image)\n",
    "                          .Conv2D('conv0', 32)\n",
    "                          .MaxPooling('pool0', 2)\n",
    "                          .Dropout('dropout', rate=0.7)\n",
    "                          .Conv2D('conv1', 64)\n",
    "                          .MaxPooling('pool1', 2)\n",
    "                          .Dropout('dropout', rate=0.7)\n",
    "                          .Conv2D('conv2', 128)\n",
    "                          .MaxPooling('pool2', 2)\n",
    "                          .Dropout('dropout', rate=0.7)\n",
    "                          .FullyConnected('fc1', units=10,\n",
    "                                          activation=tf.identity)())\n",
    "        \n",
    "        # Cost function\n",
    "        cost = tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, \n",
    "                                                           labels=label),\n",
    "            name='Loss')\n",
    "        \n",
    "        correct = tf.cast(tf.equal(tf.argmax(logits, -1, \n",
    "                                             output_type=tf.int32), \n",
    "                                   label),\n",
    "                          tf.float32)\n",
    "        accuracy = tf.reduce_mean(correct, name='accuracy')\n",
    "        train_error = tf.reduce_mean(1 - correct, name='train_error')\n",
    "        \n",
    "        summary.add_moving_summary(train_error, accuracy)\n",
    "        return cost\n",
    "\n",
    "    def optimizer(self):\n",
    "        lr = tf.train.exponential_decay(\n",
    "            learning_rate=0.001,\n",
    "            global_step=get_global_step_var(),\n",
    "            decay_steps=468 * 10,\n",
    "            decay_rate=0.3, staircase=True, name='learning_rate')\n",
    "        # for tensorboard.\n",
    "        tf.summary.scalar('lr', lr)\n",
    "        return tf.train.AdamOptimizer(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. main.py\n",
    "#### `logger` for tensorboard, `TrainConfig` for model configuration including model saver.\n",
    "* If you use **auto_set_dir()**, it makes a **`'train_log'`** directory and makes another directory in it \n",
    "   with the same name of file.py. You can see the scalars with tensorboard at there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard and datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0815 23:17:02 @logger.py:74]\u001b[0m Argv: /anaconda/lib/python3.6/site-packages/ipykernel_launcher.py -f /Users/chayesol/Library/Jupyter/runtime/kernel-77dfb712-6db0-48b7-9ba0-fe6d52be50d7.json\n"
     ]
    }
   ],
   "source": [
    "# for tensorboard \n",
    "logger.set_logger_dir('./mnist_result')\n",
    "# logger.auto_set_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataset\n",
    "df = get_dataflow(100, 'train')\n",
    "df_test = get_dataflow(100, 'test')\n",
    "\n",
    "df.reset_state()\n",
    "df_test.reset_state()\n",
    "steps_per_epoch = df.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "* `Keywords`: **TrainConfig**, **launch_train_with_config**, **SimpleTrainer**, **SyncMultiGPUTrainer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0815 23:17:06 @input_source.py:205]\u001b[0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...\n",
      "\u001b[32m[0815 23:17:06 @trainers.py:51]\u001b[0m Building graph for a single training tower ...\n",
      "\u001b[32m[0815 23:17:06 @registry.py:121]\u001b[0m conv0 input: [None, 28, 28, 1]\n",
      "\u001b[32m[0815 23:17:06 @registry.py:129]\u001b[0m conv0 output: [None, 28, 28, 32]\n",
      "\u001b[32m[0815 23:17:06 @registry.py:121]\u001b[0m pool0 input: [None, 28, 28, 32]\n",
      "\u001b[32m[0815 23:17:06 @registry.py:129]\u001b[0m pool0 output: [None, 14, 14, 32]\n",
      "\u001b[32m[0815 23:17:06 @registry.py:121]\u001b[0m conv1 input: [None, 14, 14, 32]\n",
      "\u001b[32m[0815 23:17:06 @registry.py:129]\u001b[0m conv1 output: [None, 14, 14, 64]\n",
      "\u001b[32m[0815 23:17:06 @registry.py:121]\u001b[0m pool1 input: [None, 14, 14, 64]\n",
      "\u001b[32m[0815 23:17:06 @registry.py:129]\u001b[0m pool1 output: [None, 7, 7, 64]\n",
      "\u001b[32m[0815 23:17:06 @registry.py:121]\u001b[0m conv2 input: [None, 7, 7, 64]\n",
      "\u001b[32m[0815 23:17:06 @registry.py:129]\u001b[0m conv2 output: [None, 7, 7, 128]\n",
      "\u001b[32m[0815 23:17:06 @registry.py:121]\u001b[0m pool2 input: [None, 7, 7, 128]\n",
      "\u001b[32m[0815 23:17:06 @registry.py:129]\u001b[0m pool2 output: [None, 3, 3, 128]\n",
      "\u001b[32m[0815 23:17:06 @registry.py:121]\u001b[0m fc1 input: [None, 3, 3, 128]\n",
      "\u001b[32m[0815 23:17:06 @registry.py:129]\u001b[0m fc1 output: [None, 10]\n",
      "\u001b[32m[0815 23:17:06 @model_utils.py:64]\u001b[0m \u001b[36mTrainable Variables: \n",
      "\u001b[0mname       shape              dim\n",
      "---------  ---------------  -----\n",
      "conv0/W:0  [3, 3, 1, 32]      288\n",
      "conv0/b:0  [32]                32\n",
      "conv1/W:0  [3, 3, 32, 64]   18432\n",
      "conv1/b:0  [64]                64\n",
      "conv2/W:0  [3, 3, 64, 128]  73728\n",
      "conv2/b:0  [128]              128\n",
      "fc1/W:0    [1152, 10]       11520\n",
      "fc1/b:0    [10]                10\u001b[36m\n",
      "Total #vars=8, #params=104202, size=0.40MB\u001b[0m\n",
      "\u001b[32m[0815 23:17:06 @base.py:187]\u001b[0m Setup callbacks graph ...\n",
      "\u001b[32m[0815 23:17:06 @inference_runner.py:146]\u001b[0m [InferenceRunner] Building tower 'InferenceTower' on device /gpu:0 ...\n",
      "\u001b[32m[0815 23:17:06 @summary.py:38]\u001b[0m Maintain moving average summary of 2 tensors in collection MOVING_SUMMARY_OPS.\n",
      "\u001b[32m[0815 23:17:06 @summary.py:75]\u001b[0m Summarizing collection 'summaries' of size 4.\n",
      "\u001b[32m[0815 23:17:06 @base.py:205]\u001b[0m Creating the session ...\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "\u001b[32m[0815 23:17:07 @base.py:211]\u001b[0m Initializing the session ...\n",
      "\u001b[32m[0815 23:17:07 @base.py:218]\u001b[0m Graph Finalized.\n",
      "\u001b[32m[0815 23:17:07 @concurrency.py:37]\u001b[0m Starting EnqueueThread QueueInput/input_queue ...\n",
      "\u001b[32m[0815 23:17:07 @inference_runner.py:101]\u001b[0m [InferenceRunner] Will eval 100 iterations\n",
      "\u001b[32m[0815 23:17:07 @base.py:250]\u001b[0m Start Epoch 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|600/600[01:11<00:00, 8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0815 23:18:18 @base.py:260]\u001b[0m Epoch 1 (global_step 600) finished, time:1 minute 11 seconds.\n",
      "\u001b[32m[0815 23:18:18 @saver.py:77]\u001b[0m Model saved to ./mnist_result/model-600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:04<00:00,23.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0815 23:18:23 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0815 23:18:23 @monitor.py:435]\u001b[0m accuracy: 0.66153\n",
      "\u001b[32m[0815 23:18:23 @monitor.py:435]\u001b[0m lr: 0.001\n",
      "\u001b[32m[0815 23:18:23 @monitor.py:435]\u001b[0m train_error: 0.33847\n",
      "\u001b[32m[0815 23:18:23 @monitor.py:435]\u001b[0m validation_Loss: 0.88131\n",
      "\u001b[32m[0815 23:18:23 @monitor.py:435]\u001b[0m validation_accuracy: 0.8709\n",
      "\u001b[32m[0815 23:18:23 @group.py:48]\u001b[0m Callbacks took 4.337 sec in total. InferenceRunner: 4.3 seconds\n",
      "\u001b[32m[0815 23:18:23 @base.py:250]\u001b[0m Start Epoch 2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|600/600[01:19<00:00, 8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0815 23:19:42 @base.py:260]\u001b[0m Epoch 2 (global_step 1200) finished, time:1 minute 19 seconds.\n",
      "\u001b[32m[0815 23:19:42 @saver.py:77]\u001b[0m Model saved to ./mnist_result/model-1200.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:04<00:00,24.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0815 23:19:46 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0815 23:19:46 @monitor.py:435]\u001b[0m accuracy: 0.82476\n",
      "\u001b[32m[0815 23:19:46 @monitor.py:435]\u001b[0m lr: 0.001\n",
      "\u001b[32m[0815 23:19:46 @monitor.py:435]\u001b[0m train_error: 0.17524\n",
      "\u001b[32m[0815 23:19:46 @monitor.py:435]\u001b[0m validation_Loss: 0.35229\n",
      "\u001b[32m[0815 23:19:46 @monitor.py:435]\u001b[0m validation_accuracy: 0.9368\n",
      "\u001b[32m[0815 23:19:46 @group.py:48]\u001b[0m Callbacks took 4.056 sec in total. InferenceRunner: 4.03 seconds\n",
      "\u001b[32m[0815 23:19:46 @base.py:250]\u001b[0m Start Epoch 3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|600/600[01:24<00:00, 7.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0815 23:21:11 @base.py:260]\u001b[0m Epoch 3 (global_step 1800) finished, time:1 minute 24 seconds.\n",
      "\u001b[32m[0815 23:21:11 @saver.py:77]\u001b[0m Model saved to ./mnist_result/model-1800.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:04<00:00,22.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0815 23:21:15 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0815 23:21:15 @monitor.py:435]\u001b[0m accuracy: 0.87428\n",
      "\u001b[32m[0815 23:21:15 @monitor.py:435]\u001b[0m lr: 0.001\n",
      "\u001b[32m[0815 23:21:15 @monitor.py:435]\u001b[0m train_error: 0.12572\n",
      "\u001b[32m[0815 23:21:15 @monitor.py:435]\u001b[0m validation_Loss: 0.19803\n",
      "\u001b[32m[0815 23:21:15 @monitor.py:435]\u001b[0m validation_accuracy: 0.9617\n",
      "\u001b[32m[0815 23:21:15 @group.py:48]\u001b[0m Callbacks took 4.574 sec in total. InferenceRunner: 4.53 seconds\n",
      "\u001b[32m[0815 23:21:15 @base.py:250]\u001b[0m Start Epoch 4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|600/600[01:10<00:00, 8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0815 23:22:26 @base.py:260]\u001b[0m Epoch 4 (global_step 2400) finished, time:1 minute 10 seconds.\n",
      "\u001b[32m[0815 23:22:26 @saver.py:77]\u001b[0m Model saved to ./mnist_result/model-2400.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:03<00:00,26.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0815 23:22:30 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0815 23:22:30 @monitor.py:435]\u001b[0m accuracy: 0.9054\n",
      "\u001b[32m[0815 23:22:30 @monitor.py:435]\u001b[0m lr: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0815 23:22:30 @monitor.py:435]\u001b[0m train_error: 0.094598\n",
      "\u001b[32m[0815 23:22:30 @monitor.py:435]\u001b[0m validation_Loss: 0.13497\n",
      "\u001b[32m[0815 23:22:30 @monitor.py:435]\u001b[0m validation_accuracy: 0.9703\n",
      "\u001b[32m[0815 23:22:30 @group.py:48]\u001b[0m Callbacks took 3.852 sec in total. InferenceRunner: 3.83 seconds\n",
      "\u001b[32m[0815 23:22:30 @base.py:250]\u001b[0m Start Epoch 5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|600/600[01:14<00:00, 8.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0815 23:23:44 @base.py:260]\u001b[0m Epoch 5 (global_step 3000) finished, time:1 minute 14 seconds.\n",
      "\u001b[32m[0815 23:23:44 @saver.py:77]\u001b[0m Model saved to ./mnist_result/model-3000.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:04<00:00,23.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0815 23:23:48 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0815 23:23:48 @monitor.py:435]\u001b[0m accuracy: 0.91092\n",
      "\u001b[32m[0815 23:23:48 @monitor.py:435]\u001b[0m lr: 0.001\n",
      "\u001b[32m[0815 23:23:48 @monitor.py:435]\u001b[0m train_error: 0.089081\n",
      "\u001b[32m[0815 23:23:48 @monitor.py:435]\u001b[0m validation_Loss: 0.11393\n",
      "\u001b[32m[0815 23:23:48 @monitor.py:435]\u001b[0m validation_accuracy: 0.9757\n",
      "\u001b[32m[0815 23:23:48 @group.py:48]\u001b[0m Callbacks took 4.238 sec in total. InferenceRunner: 4.21 seconds\n",
      "\u001b[32m[0815 23:23:48 @base.py:250]\u001b[0m Start Epoch 6 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|600/600[01:17<00:00, 7.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0815 23:25:06 @base.py:260]\u001b[0m Epoch 6 (global_step 3600) finished, time:1 minute 17 seconds.\n",
      "\u001b[32m[0815 23:25:06 @saver.py:77]\u001b[0m Model saved to ./mnist_result/model-3600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:04<00:00,23.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0815 23:25:10 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0815 23:25:10 @monitor.py:435]\u001b[0m accuracy: 0.92217\n",
      "\u001b[32m[0815 23:25:10 @monitor.py:435]\u001b[0m lr: 0.001\n",
      "\u001b[32m[0815 23:25:10 @monitor.py:435]\u001b[0m train_error: 0.077829\n",
      "\u001b[32m[0815 23:25:10 @monitor.py:435]\u001b[0m validation_Loss: 0.09538\n",
      "\u001b[32m[0815 23:25:10 @monitor.py:435]\u001b[0m validation_accuracy: 0.978\n",
      "\u001b[32m[0815 23:25:10 @group.py:48]\u001b[0m Callbacks took 4.209 sec in total. InferenceRunner: 4.18 seconds\n",
      "\u001b[32m[0815 23:25:10 @base.py:250]\u001b[0m Start Epoch 7 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|600/600[01:14<00:00, 8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0815 23:26:25 @base.py:260]\u001b[0m Epoch 7 (global_step 4200) finished, time:1 minute 14 seconds.\n",
      "\u001b[32m[0815 23:26:25 @saver.py:77]\u001b[0m Model saved to ./mnist_result/model-4200.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:04<00:00,24.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0815 23:26:29 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0815 23:26:29 @monitor.py:435]\u001b[0m accuracy: 0.92945\n",
      "\u001b[32m[0815 23:26:29 @monitor.py:435]\u001b[0m lr: 0.001\n",
      "\u001b[32m[0815 23:26:29 @monitor.py:435]\u001b[0m train_error: 0.070552\n",
      "\u001b[32m[0815 23:26:29 @monitor.py:435]\u001b[0m validation_Loss: 0.085823\n",
      "\u001b[32m[0815 23:26:29 @monitor.py:435]\u001b[0m validation_accuracy: 0.9814\n",
      "\u001b[32m[0815 23:26:29 @group.py:48]\u001b[0m Callbacks took 4.169 sec in total. InferenceRunner: 4.15 seconds\n",
      "\u001b[32m[0815 23:26:29 @base.py:250]\u001b[0m Start Epoch 8 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|600/600[01:17<00:00, 7.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0815 23:27:47 @base.py:260]\u001b[0m Epoch 8 (global_step 4800) finished, time:1 minute 17 seconds.\n",
      "\u001b[32m[0815 23:27:47 @saver.py:77]\u001b[0m Model saved to ./mnist_result/model-4800.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:04<00:00,22.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0815 23:27:52 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0815 23:27:52 @monitor.py:435]\u001b[0m accuracy: 0.9334\n",
      "\u001b[32m[0815 23:27:52 @monitor.py:435]\u001b[0m lr: 0.0003\n",
      "\u001b[32m[0815 23:27:52 @monitor.py:435]\u001b[0m train_error: 0.066598\n",
      "\u001b[32m[0815 23:27:52 @monitor.py:435]\u001b[0m validation_Loss: 0.070099\n",
      "\u001b[32m[0815 23:27:52 @monitor.py:435]\u001b[0m validation_accuracy: 0.984\n",
      "\u001b[32m[0815 23:27:52 @group.py:48]\u001b[0m Callbacks took 4.390 sec in total. InferenceRunner: 4.37 seconds\n",
      "\u001b[32m[0815 23:27:52 @base.py:250]\u001b[0m Start Epoch 9 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|600/600[01:16<00:00, 7.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0815 23:29:08 @base.py:260]\u001b[0m Epoch 9 (global_step 5400) finished, time:1 minute 16 seconds.\n",
      "\u001b[32m[0815 23:29:08 @saver.py:77]\u001b[0m Model saved to ./mnist_result/model-5400.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:04<00:00,20.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0815 23:29:13 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0815 23:29:13 @monitor.py:435]\u001b[0m accuracy: 0.93811\n",
      "\u001b[32m[0815 23:29:13 @monitor.py:435]\u001b[0m lr: 0.0003\n",
      "\u001b[32m[0815 23:29:13 @monitor.py:435]\u001b[0m train_error: 0.061893\n",
      "\u001b[32m[0815 23:29:13 @monitor.py:435]\u001b[0m validation_Loss: 0.067997\n",
      "\u001b[32m[0815 23:29:13 @monitor.py:435]\u001b[0m validation_accuracy: 0.9843\n",
      "\u001b[32m[0815 23:29:13 @group.py:48]\u001b[0m Callbacks took 4.934 sec in total. InferenceRunner: 4.9 seconds\n",
      "\u001b[32m[0815 23:29:13 @base.py:250]\u001b[0m Start Epoch 10 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|600/600[01:26<00:00, 6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0815 23:30:39 @base.py:260]\u001b[0m Epoch 10 (global_step 6000) finished, time:1 minute 26 seconds.\n",
      "\u001b[32m[0815 23:30:39 @saver.py:77]\u001b[0m Model saved to ./mnist_result/model-6000.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:04<00:00,22.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0815 23:30:44 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0815 23:30:44 @monitor.py:435]\u001b[0m accuracy: 0.94331\n",
      "\u001b[32m[0815 23:30:44 @monitor.py:435]\u001b[0m lr: 0.0003\n",
      "\u001b[32m[0815 23:30:44 @monitor.py:435]\u001b[0m train_error: 0.056693\n",
      "\u001b[32m[0815 23:30:44 @monitor.py:435]\u001b[0m validation_Loss: 0.064552\n",
      "\u001b[32m[0815 23:30:44 @monitor.py:435]\u001b[0m validation_accuracy: 0.9852\n",
      "\u001b[32m[0815 23:30:44 @group.py:48]\u001b[0m Callbacks took 4.521 sec in total. InferenceRunner: 4.5 seconds\n",
      "\u001b[32m[0815 23:30:44 @base.py:264]\u001b[0m Training has finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0815 23:30:44 @input_source.py:160]\u001b[0m EnqueueThread QueueInput/input_queue Exited.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Configuration containing everything necessary in a training.\n",
    "\"\"\"\n",
    "config = TrainConfig(\n",
    "    model = Model(),\n",
    "    data = QueueInput(df),\n",
    "    callbacks = [\n",
    "        # save the model after every epoch\n",
    "        ModelSaver(checkpoint_dir='./mnist_result'),\n",
    "        InferenceRunner(\n",
    "            df_test,\n",
    "            ScalarStats(['Loss', 'accuracy'])),\n",
    "            #  ScheduledHyperParamSetter('learning_rate',\n",
    "            #                            [(1, 0.1), \n",
    "            #                             (300, 0.01), \n",
    "            #                             (500, 0.001)])\n",
    "    ],\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    max_epoch = 10,\n",
    ")\n",
    "\n",
    "# training with CPU or GPU?\n",
    "if tf.test.gpu_device_name():\n",
    "    launch_train_with_config(config, SyncMultiGPUTrainer(4))\n",
    "else:\n",
    "    launch_train_with_config(config, SimpleTrainer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. Loading The Saved Model \n",
    "#### Loading saved model and learning 5 epochs more.\n",
    "##### In tensorflow, \n",
    "* **`.meta`** file means **the structure** of model, \n",
    "    all **variables, and operations.** \n",
    "* **`index`** means a binary file contating **weights, biases, and gradients**.\n",
    "\n",
    "* We are going to use **`PredictConfig`** to evaluate the loaded and more trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Transfer Learning\n",
    "* If you have any trouble with it, then consider **`logger.set_logger_dir(path_to_saved_model)`** carefully.\n",
    "* `Keywords`: **AutoResumeTrainConfig**, **sesseion_init**, **get_model_loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:38:06 @varmanip.py:182]\u001b[0m Checkpoint path ./mnist_result/model-6000.index is auto-corrected to ./mnist_result/model-6000.\n",
      "\u001b[32m[0814 17:38:06 @config.py:215]\u001b[0m Found checkpoint at ./mnist_result/model-6000. session_init arguments will be overwritten.\n",
      "\u001b[32m[0814 17:38:06 @config.py:225]\u001b[0m Found history statistics from JSON. Overwrite the starting epoch to epoch #11.\n",
      "\u001b[32m[0814 17:38:06 @input_source.py:205]\u001b[0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...\n",
      "\u001b[32m[0814 17:38:06 @trainers.py:51]\u001b[0m Building graph for a single training tower ...\n",
      "\u001b[32m[0814 17:38:06 @registry.py:121]\u001b[0m conv0 input: [None, 28, 28, 1]\n",
      "\u001b[32m[0814 17:38:06 @registry.py:129]\u001b[0m conv0 output: [None, 28, 28, 32]\n",
      "\u001b[32m[0814 17:38:06 @registry.py:121]\u001b[0m pool0 input: [None, 28, 28, 32]\n",
      "\u001b[32m[0814 17:38:06 @registry.py:129]\u001b[0m pool0 output: [None, 14, 14, 32]\n",
      "\u001b[32m[0814 17:38:06 @registry.py:121]\u001b[0m conv1 input: [None, 14, 14, 32]\n",
      "\u001b[32m[0814 17:38:06 @registry.py:129]\u001b[0m conv1 output: [None, 14, 14, 64]\n",
      "\u001b[32m[0814 17:38:06 @registry.py:121]\u001b[0m pool1 input: [None, 14, 14, 64]\n",
      "\u001b[32m[0814 17:38:06 @registry.py:129]\u001b[0m pool1 output: [None, 7, 7, 64]\n",
      "\u001b[32m[0814 17:38:06 @registry.py:121]\u001b[0m conv2 input: [None, 7, 7, 64]\n",
      "\u001b[32m[0814 17:38:06 @registry.py:129]\u001b[0m conv2 output: [None, 7, 7, 128]\n",
      "\u001b[32m[0814 17:38:06 @registry.py:121]\u001b[0m pool2 input: [None, 7, 7, 128]\n",
      "\u001b[32m[0814 17:38:06 @registry.py:129]\u001b[0m pool2 output: [None, 3, 3, 128]\n",
      "\u001b[32m[0814 17:38:06 @registry.py:121]\u001b[0m fc1 input: [None, 3, 3, 128]\n",
      "\u001b[32m[0814 17:38:06 @registry.py:129]\u001b[0m fc1 output: [None, 10]\n",
      "\u001b[32m[0814 17:38:07 @model_utils.py:64]\u001b[0m \u001b[36mTrainable Variables: \n",
      "\u001b[0mname       shape              dim\n",
      "---------  ---------------  -----\n",
      "conv0/W:0  [3, 3, 1, 32]      288\n",
      "conv0/b:0  [32]                32\n",
      "conv1/W:0  [3, 3, 32, 64]   18432\n",
      "conv1/b:0  [64]                64\n",
      "conv2/W:0  [3, 3, 64, 128]  73728\n",
      "conv2/b:0  [128]              128\n",
      "fc1/W:0    [1152, 10]       11520\n",
      "fc1/b:0    [10]                10\u001b[36m\n",
      "Total #vars=8, #params=104202, size=0.40MB\u001b[0m\n",
      "\u001b[32m[0814 17:38:07 @base.py:187]\u001b[0m Setup callbacks graph ...\n",
      "\u001b[32m[0814 17:38:07 @inference_runner.py:146]\u001b[0m [InferenceRunner] Building tower 'InferenceTower' on device /gpu:0 ...\n",
      "\u001b[32m[0814 17:38:07 @summary.py:38]\u001b[0m Maintain moving average summary of 2 tensors in collection MOVING_SUMMARY_OPS.\n",
      "\u001b[32m[0814 17:38:07 @summary.py:75]\u001b[0m Summarizing collection 'summaries' of size 4.\n",
      "\u001b[32m[0814 17:38:07 @base.py:205]\u001b[0m Creating the session ...\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "\u001b[32m[0814 17:38:07 @base.py:211]\u001b[0m Initializing the session ...\n",
      "\u001b[32m[0814 17:38:07 @sessinit.py:117]\u001b[0m Restoring checkpoint from ./mnist_result/model-6000 ...\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_result/model-6000\n",
      "\u001b[32m[0814 17:38:07 @base.py:218]\u001b[0m Graph Finalized.\n",
      "\u001b[32m[0814 17:38:07 @concurrency.py:37]\u001b[0m Starting EnqueueThread QueueInput/input_queue ...\n",
      "\u001b[32m[0814 17:38:07 @steps.py:126]\u001b[0m Start training with global_step=6000\n",
      "\u001b[32m[0814 17:38:07 @inference_runner.py:101]\u001b[0m [InferenceRunner] Will eval 100 iterations\n",
      "\u001b[32m[0814 17:38:07 @monitor.py:317]\u001b[0m Found existing JSON inside ./mnist_result, will append to it.\n",
      "\u001b[32m[0814 17:38:07 @base.py:250]\u001b[0m Start Epoch 11 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|600/600[01:26<00:00, 6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:39:34 @base.py:260]\u001b[0m Epoch 11 (global_step 6600) finished, time:1 minute 26 seconds.\n",
      "\u001b[32m[0814 17:39:34 @saver.py:77]\u001b[0m Model saved to ./transfer/model-6600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:05<00:00,18.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:39:39 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0814 17:39:39 @monitor.py:435]\u001b[0m accuracy: 0.94823\n",
      "\u001b[32m[0814 17:39:39 @monitor.py:435]\u001b[0m lr: 0.0003\n",
      "\u001b[32m[0814 17:39:39 @monitor.py:435]\u001b[0m train_error: 0.051774\n",
      "\u001b[32m[0814 17:39:39 @monitor.py:435]\u001b[0m validation_Loss: 0.061184\n",
      "\u001b[32m[0814 17:39:39 @monitor.py:435]\u001b[0m validation_accuracy: 0.9856\n",
      "\u001b[32m[0814 17:39:39 @group.py:48]\u001b[0m Callbacks took 5.574 sec in total. InferenceRunner: 5.55 seconds\n",
      "\u001b[32m[0814 17:39:39 @base.py:250]\u001b[0m Start Epoch 12 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|600/600[01:26<00:00, 7.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:41:05 @base.py:260]\u001b[0m Epoch 12 (global_step 7200) finished, time:1 minute 26 seconds.\n",
      "\u001b[32m[0814 17:41:05 @saver.py:77]\u001b[0m Model saved to ./transfer/model-7200.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:05<00:00,17.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:41:11 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0814 17:41:11 @monitor.py:435]\u001b[0m accuracy: 0.94186\n",
      "\u001b[32m[0814 17:41:11 @monitor.py:435]\u001b[0m lr: 0.0003\n",
      "\u001b[32m[0814 17:41:11 @monitor.py:435]\u001b[0m train_error: 0.058136\n",
      "\u001b[32m[0814 17:41:11 @monitor.py:435]\u001b[0m validation_Loss: 0.057191\n",
      "\u001b[32m[0814 17:41:11 @monitor.py:435]\u001b[0m validation_accuracy: 0.9856\n",
      "\u001b[32m[0814 17:41:11 @group.py:48]\u001b[0m Callbacks took 5.628 sec in total. InferenceRunner: 5.61 seconds\n",
      "\u001b[32m[0814 17:41:11 @base.py:250]\u001b[0m Start Epoch 13 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|600/600[01:26<00:00, 6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:42:38 @base.py:260]\u001b[0m Epoch 13 (global_step 7800) finished, time:1 minute 26 seconds.\n",
      "\u001b[32m[0814 17:42:38 @saver.py:77]\u001b[0m Model saved to ./transfer/model-7800.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:06<00:00,16.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:42:44 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0814 17:42:44 @monitor.py:435]\u001b[0m accuracy: 0.94769\n",
      "\u001b[32m[0814 17:42:44 @monitor.py:435]\u001b[0m lr: 0.0003\n",
      "\u001b[32m[0814 17:42:44 @monitor.py:435]\u001b[0m train_error: 0.052311\n",
      "\u001b[32m[0814 17:42:44 @monitor.py:435]\u001b[0m validation_Loss: 0.056378\n",
      "\u001b[32m[0814 17:42:44 @monitor.py:435]\u001b[0m validation_accuracy: 0.9857\n",
      "\u001b[32m[0814 17:42:44 @group.py:48]\u001b[0m Callbacks took 6.237 sec in total. InferenceRunner: 6.21 seconds\n",
      "\u001b[32m[0814 17:42:44 @base.py:250]\u001b[0m Start Epoch 14 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|600/600[01:26<00:00, 7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:44:10 @base.py:260]\u001b[0m Epoch 14 (global_step 8400) finished, time:1 minute 26 seconds.\n",
      "\u001b[32m[0814 17:44:10 @saver.py:77]\u001b[0m Model saved to ./transfer/model-8400.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:05<00:00,18.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:44:16 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0814 17:44:16 @monitor.py:435]\u001b[0m accuracy: 0.94692\n",
      "\u001b[32m[0814 17:44:16 @monitor.py:435]\u001b[0m lr: 0.0003\n",
      "\u001b[32m[0814 17:44:16 @monitor.py:435]\u001b[0m train_error: 0.053084\n",
      "\u001b[32m[0814 17:44:16 @monitor.py:435]\u001b[0m validation_Loss: 0.056021\n",
      "\u001b[32m[0814 17:44:16 @monitor.py:435]\u001b[0m validation_accuracy: 0.9871\n",
      "\u001b[32m[0814 17:44:16 @group.py:48]\u001b[0m Callbacks took 5.374 sec in total. InferenceRunner: 5.36 seconds\n",
      "\u001b[32m[0814 17:44:16 @base.py:250]\u001b[0m Start Epoch 15 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|600/600[01:24<00:00, 7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:45:41 @base.py:260]\u001b[0m Epoch 15 (global_step 9000) finished, time:1 minute 24 seconds.\n",
      "\u001b[32m[0814 17:45:41 @saver.py:77]\u001b[0m Model saved to ./transfer/model-9000.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:05<00:00,18.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:45:46 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0814 17:45:46 @monitor.py:435]\u001b[0m accuracy: 0.95449\n",
      "\u001b[32m[0814 17:45:46 @monitor.py:435]\u001b[0m lr: 0.0003\n",
      "\u001b[32m[0814 17:45:46 @monitor.py:435]\u001b[0m train_error: 0.045515\n",
      "\u001b[32m[0814 17:45:46 @monitor.py:435]\u001b[0m validation_Loss: 0.052748\n",
      "\u001b[32m[0814 17:45:46 @monitor.py:435]\u001b[0m validation_accuracy: 0.9865\n",
      "\u001b[32m[0814 17:45:46 @group.py:48]\u001b[0m Callbacks took 5.291 sec in total. InferenceRunner: 5.27 seconds\n",
      "\u001b[32m[0814 17:45:46 @base.py:264]\u001b[0m Training has finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:45:46 @input_source.py:160]\u001b[0m EnqueueThread QueueInput/input_queue Exited.\n"
     ]
    }
   ],
   "source": [
    "config = AutoResumeTrainConfig(\n",
    "    model = Model(),\n",
    "    session_init = get_model_loader('./mnist_result/model-6000.index'),\n",
    "    data = QueueInput(df),\n",
    "    callbacks = [\n",
    "        # save the model after every epoch\n",
    "        ModelSaver(checkpoint_dir='./transfer'),\n",
    "        InferenceRunner(\n",
    "            df_test,\n",
    "            ScalarStats(['Loss', 'accuracy'])),\n",
    "#         ScheduledHyperParamSetter('learning_rate',\n",
    "#                                   [(1, 0.1), \n",
    "#                                    (300, 0.01), \n",
    "#                                    (500, 0.001)])\n",
    "    ],\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    max_epoch = 15,\n",
    ")\n",
    "\n",
    "launch_train_with_config(config, SimpleTrainer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "* `Keywords`: **PredictConfig**, **SimpleDatasetPredictor**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 15:31:02 @varmanip.py:182]\u001b[0m Checkpoint path ./mnist_result/model-6000.index is auto-corrected to ./mnist_result/model-6000.\n",
      "\u001b[32m[0814 15:31:02 @sessinit.py:90]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The following variables are in the checkpoint, but not found in the graph: beta1_power:0, beta2_power:0, global_step:0\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "\u001b[32m[0814 15:31:02 @sessinit.py:117]\u001b[0m Restoring checkpoint from ./mnist_result/model-6000 ...\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_result/model-6000\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "session = get_model_loader('./mnist_result/model-6000.index')\n",
    "\n",
    "pred_config = PredictConfig(\n",
    "        model=model,\n",
    "        session_init=session,\n",
    "        input_names=['input', 'label'],\n",
    "        output_names=['accuracy', 'Loss']\n",
    "    )\n",
    "pred = SimpleDatasetPredictor(pred_config, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|100/100[00:04<00:00,20.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.985\n",
      "Loss: 0.067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0.0\n",
    "total_loss = 0.0\n",
    "\n",
    "for i, (acc, loss) in enumerate(pred.get_result()):\n",
    "    accuracy += acc \n",
    "    total_loss += loss\n",
    "    \n",
    "print(\"Accuracy: {:0.3f}\".format(accuracy/(i+1)))\n",
    "print(\"Loss: {:0.3f}\".format(total_loss/(i+1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
