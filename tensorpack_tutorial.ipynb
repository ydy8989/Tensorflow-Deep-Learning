{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorpack tutorial \n",
    "#### In this tutorial, we are going to cover following steps.\n",
    "* **Data Loading** (Dataflow)\n",
    "* **Build a model**\n",
    "* **Training & test** (CPU, GPU, or MultiGPU)\n",
    "* **Trasfer learning** (Loading a saved Model and training it agiain)\n",
    "* **Evaluation** (Loading a saved Model and test it)\n",
    "\n",
    "#### You can find more specific explanations per function in [here](https://tensorpack.readthedocs.io/modules/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2           # for AugmentImageComponent\n",
    "import multiprocessing\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from tensorpack import *\n",
    "from tensorpack.dataflow import *\n",
    "from tensorpack.tfutils import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get DataFlow\n",
    "* You can **augment** your data in here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dataflow(batch_size, is_train='train'):\n",
    "    df = dataset.Mnist(is_train, shuffle=True)\n",
    "\n",
    "    # ----- Image Augmentation Options -------- #\n",
    "    if is_train is 'train':\n",
    "        augs = [\n",
    "            #   imgaug.CenterCrop(256, 256),\n",
    "            #   imgaug.Resize((225, 225)),\n",
    "            #   imgaug.Grayscale(keepdims=True),\n",
    "#                imgaug.Flip(horiz=True, vert=False, prob=0.5),\n",
    "        ]\n",
    "    else:\n",
    "        augs = [\n",
    "            #   imgaug.CenterCrop(256, 256),\n",
    "            #   imgaug.Resize((225, 225)),\n",
    "        ]\n",
    "    df = AugmentImageComponent(df, augs)\n",
    "    # group data into batches of size 128\n",
    "    df = BatchData(df, batch_size)\n",
    "    # start 3 processes to run the dataflow in parallel\n",
    "    # df = PrefetchDataZMQ(df, 10, multiprocessing.cpu_count())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABkAAAAF2CAYAAAA2iFSZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XvQXWV9L/DfYy4toTCKJUgRpCri\nQSu3DJxRR3AYiDFlxJG2xl4AteQPLDLFAsGhWI8o2HKZikKhMMit2BGCUE9BpB3xwBkGglDgcDHQ\nHCFiEmRoIlS5PeePvBwjTcj7e7PXu/d+1uczw+TNznft9TzsYX3Z/Fh7l1prAAAAAAAAtOQ1w14A\nAAAAAADAoBmAAAAAAAAAzTEAAQAAAAAAmmMAAgAAAAAANMcABAAAAAAAaI4BCAAAAAAA0BwDEAAA\nAAAAoDkGIAAAAAAAQHMMQAAAAAAAgObMnM6TlVLqdJ4PoGFP1lq3H/YiRoV+ARiMWmsZ9hpGhW4B\nGBjvXTagXwAGY7LvXdwBAjCe/u+wFwAAADAJ3rsAMDQGIAAAAAAAQHO2aABSSvlAKeWhUsryUspJ\ng1oUAP2mXwAYNN0CQBf0C8Bom/IApJQyIyK+GhELImKPiFhUStljUAsDoJ/0CwCDplsA6IJ+ARh9\nW3IHyH4RsbzW+mit9bmIuCoiPjSYZQHQY/oFgEHTLQB0Qb8AjLgtGYDsFBGPbfD7xyce+xWllKNL\nKXeWUu7cgnMB0B/6BYBB0y0AdEG/AIy4mVtwbNnIY/W/PFDrBRFxQUREKeW//DkAvIJ+AWDQdAsA\nXdAvACNuS+4AeTwidt7g92+MiB9v2XIAQL8AMHC6BYAu6BeAEbclA5A7ImK3Uspvl1JmR8RHI+K6\nwSwLgB7TLwAMmm4BoAv6BWDETfkjsGqtL5RSPhURN0bEjIi4uNZ6/8BWBkAv6RcABk23ANAF/QIw\n+kqt0/fRgz7nEGBgltVa5w17EaNCvwAMRq11Y59l3ku6BWBgvHfZgH4BGIzJvnfZko/AAgAAAAAA\nGEkGIAAAAAAAQHMMQAAAAAAAgOYYgAAAAAAAAM0xAAEAAAAAAJpjAAIAAAAAADTHAAQAAAAAAGiO\nAQgAAAAAANAcAxAAAAAAAKA5BiAAAAAAAEBzDEAAAAAAAIDmGIAAAAAAAADNMQABAAAAAACaYwAC\nAAAAAAA0xwAEAAAAAABojgEIAAAAAADQHAMQAAAAAACgOQYgAAAAAABAcwxAAAAAAACA5hiAAAAA\nAAAAzTEAAQAAAAAAmmMAAgAAAAAANMcABAAAAAAAaI4BCAAAAAAA0BwDEAAAAAAAoDkGIAAAAAAA\nQHMMQAAAAAAAgOYYgAAAAAAAAM0xAAEAAAAAAJpjAAIAAAAAADTHAAQAAAAAAGiOAQgAAAAAANAc\nAxAAAAAAAKA5BiAAAAAAAEBzDEAAAAAAAIDmGIAAAAAAAADNMQABAAAAAACaM3PYC6AtW221VfqY\ns88+O5VfvHhxKn/LLbek8h/72MdS+ZUrV6byAEyPOXPmpPIf+chHUvlDDjkklf+jP/qjVP7ee+9N\n5T//+c+n8ldffXUqHxFRa00fA9BnO+ywQyq/zz77pPJLlixJ5e+///5UPuvUU09NH7N69eoOVjJ9\nPvrRj6byRxxxRCq/YMGCVB7YvE9+8pOp/Pvf//5UfpdddknlIyLe+973pvJr1qxJ5W+66aZU/ppr\nrknlp/LeAqaLO0AAAAAAAIDmGIAAAAAAAADNMQABAAAAAACaYwACAAAAAAA0xwAEAAAAAABojgEI\nAAAAAADQHAMQAAAAAACgOQYgAAAAAABAcwxAAAAAAACA5hiAAAAAAAAAzTEAAQAAAAAAmlNqrdN3\nslKm72QMxU477ZQ+5kc/+lEHK5m6733ve6n8/PnzU/nnn38+lYdNWFZrnTfsRYwK/dK+t771relj\nrrnmmlT+He94Ryr/85//PJVfuXJlKr/LLruk8rNmzUrljzrqqFQ+IuLSSy9NH8N4qbWWYa9hVOgW\nBmHJkiWp/GmnndbRSqZm+fLlqfzXvva19DnOOeec9DFd+pM/+ZNU/qyzzkrlTz755FT+ggsuSOVH\nlPcuG9Avm3f44Yen8meffXYq/4Y3vCGVX716dSr/8MMPp/LTYf/990/lZ8+encrfeuutqfwBBxyQ\nysPGTPa9iztAAAAAAACA5szckoNLKSsiYl1EvBgRL5joAzAI+gWALugXAAZNtwCMti0agEx4f631\nyQE8DwBsSL8A0AX9AsCg6RaAEeUjsAAAAAAAgOZs6QCkRsR3SinLSilHD2JBABD6BYBu6BcABk23\nAIywLf0IrPfUWn9cSpkbETeVUh6std6yYWDi4q8AAMjQLwB04VX7RbcAMAXeuwCMsC26A6TW+uOJ\nX1dHxNKI2G8jmQtqrfN8CRQAk6VfAOjC5vpFtwCQ5b0LwGib8gCklLJ1KWWbl3+OiEMi4r5BLQyA\nftIvAHRBvwAwaLoFYPRtyUdg7RARS0spLz/PlbXWGwayKgD6TL8A0AX9AsCg6RaAETflAUit9dGI\n2HOAawEA/QJAJ/QLAIOmWwBG3xZ9BwgAAAAAAMAo2pKPwIL/4he/+EX6mOXLl6fyb33rW9PnyDjg\ngANS+RkzZqTyzz//fCoP0KIFCxak8t/61rfS58hen//93/89lf/Sl76Uyl900UWp/GmnnZbKn3TS\nSan8V7/61VQ+IuLGG29M5VetWpU+BwCTd/3116fyixYtSuVfeOGFVP65555L5adi1qxZqfyBBx6Y\nymf78Zxzzknl//7v/z6Vhz564xvfmMrffPPNqfzVV1+dyn//+99P5Z9++ulUfjrsvvvuqfxZZ52V\nyr/73e9O5bfddttUfu3atak8bMgdIAAAAAAAQHMMQAAAAAAAgOYYgAAAAAAAAM0xAAEAAAAAAJpj\nAAIAAAAAADTHAAQAAAAAAGiOAQgAAAAAANAcAxAAAAAAAKA5BiAAAAAAAEBzDEAAAAAAAIDmGIAA\nAAAAAADNmTnsBdCWJ598Mn3MOeeck8qfe+656XN06aijjkrlzzvvvI5WAjA8O+64Yyr/+c9/PpV/\nzWvy/8/GSSedlMpfdtllqfxPfvKTVD5rn3326fT558yZkz7m+OOPT+VPOOGE9DkAmLxbb701lX/2\n2Wc7Wsn0OeOMM1L54447LpX/wQ9+kMp/5StfSeVfeumlVB76KPvfidi8FStWpPLbb799Kj979uxU\nfu7cuan82rVrU3nYkDtAAAAAAACA5hiAAAAAAAAAzTEAAQAAAAAAmmMAAgAAAAAANMcABAAAAAAA\naI4BCAAAAAAA0BwDEAAAAAAAoDkGIAAAAAAAQHMMQAAAAAAAgOYYgAAAAAAAAM0xAAEAAAAAAJoz\nc9gLgHF36KGHpvLnnXdeRysBGJ5LLrkkld9nn31S+XvuuSeVj4j467/+6/QxXTrwwANT+QMOOCCV\nf+ihh1L5t73tbal8RMSxxx6byv/Lv/xLKn/DDTek8gCj7plnnun0+T/72c+m8l/+8pc7Wsl6s2bN\nSh9z+umnp/Kf/vSnU/m77rorlV+wYEEqv2bNmlQeYBh22223VH7evHmp/MqVK1P55cuXp/KwJdwB\nAgAAAAAANMcABAAAAAAAaI4BCAAAAAAA0BwDEAAAAAAAoDkGIAAAAAAAQHMMQAAAAAAAgOYYgAAA\nAAAAAM0xAAEAAAAAAJpjAAIAAAAAADTHAAQAAAAAAGiOAQgAAAAAANCcmcNeAIy7t7zlLan8vvvu\nm8ovW7YslQcYhF122SWV32OPPVL5e++9N5U/5JBDUvlRdPvtt6fyX/7yl1P5Cy+8MJX/5je/mcpH\nROy3336p/Gtf+9r0OQBacvHFF6fyJ554Yio/d+7cVH7nnXdO5bM+85nPpI/5sz/7s1Q++/5o4cKF\nqfyaNWtSeYBhmDFjRip/9NFHd7SS9aby3gKmiztAAAAAAACA5hiAAAAAAAAAzTEAAQAAAAAAmmMA\nAgAAAAAANMcABAAAAAAAaI4BCAAAAAAA0BwDEAAAAAAAoDkGIAAAAAAAQHMMQAAAAAAAgOYYgAAA\nAAAAAM0xAAEAAAAAAJpTaq3Td7JSpu9kjI25c+em8tdee20qv//++6fyXTvmmGNS+fPPP7+jlTDm\nltVa5w17EaNCvwzeDTfckMoffPDBqfxXvvKVVP64445L5dm8BQsWpI/5p3/6p1T+scceS+UPOuig\nVP6RRx5J5dm8WmsZ9hpGhW5hGE444YRU/vTTT0/lH3zwwVS+lNwlYffdd0/lIyLuvvvuVH7+/Pmp\n/Jo1a1J5OuG9ywb0C4OwaNGiVP6KK65I5VevXp3K77HHHqn8U089lcrDxkz2vYs7QAAAAAAAgOYY\ngAAAAAAAAM3Z7ACklHJxKWV1KeW+DR7brpRyUynlhxO/vq7bZQLQGv0CQBf0CwCDplsAxtdk7gC5\nJCI+8IrHToqIm2utu0XEzRO/B4CMS0K/ADB4l4R+AWCwLgndAjCWNjsAqbXeEhGv/GaaD0XE1yd+\n/npEHDbgdQHQOP0CQBf0CwCDplsAxtdUvwNkh1rrExERE7/OHdySAOgx/QJAF/QLAIOmWwDGwMyu\nT1BKOToiju76PAD0i34BYNB0CwBd0C8AwzPVO0BWlVJ2jIiY+HX1poK11gtqrfNqrfOmeC4A+kO/\nANCFSfWLbgEgwXsXgDEw1QHIdRFxxMTPR0TEtwazHAB6Tr8A0AX9AsCg6RaAMbDZAUgp5R8i4n9H\nxO6llMdLKZ+IiNMj4uBSyg8j4uCJ3wPApOkXALqgXwAYNN0CML42+x0gtdZFm/ijgwa8FgB6RL8A\n0AX9AsCg6RaA8TXVj8ACAAAAAAAYWZu9AwS6tnr1Jr8nbKPWrl3b0Uqmx/ve975U/rLLLkuf45ln\nnkkfA7Rt1qxZqfzWW2/d0UrWO/PMMzt9fjbvlltuSR/z7LPPpvI777xzKv+ud70rlX/kkUdSeYBR\nd/vtt3f6/G9/+9s7ff477rgjfcyhhx6ayq9ZsyZ9DoBRd+SRR6byX/va11L5devWpfKLFm3qpqeN\ne+qpp1J5mE7uAAEAAAAAAJpjAAIAAAAAADTHAAQAAAAAAGiOAQgAAAAAANAcAxAAAAAAAKA5BiAA\nAAAAAEBzDEAAAAAAAIDmGIAAAAAAAADNMQABAAAAAACaYwACAAAAAAA0xwAEAAAAAABozsxhLwD6\n5g/+4A9S+eOPPz59jmeeeSZ9DNC2vffeO5V/97vfncqvXbs2lX/++edTeQZvKl1x5plnpvKnnHJK\nKn/MMcek8kuXLk3lAUbda14z3v+P4u/+7u+mj1mzZk0HKwHYtNmzZ6fy2f+Oc/jhh6fyEfnrZykl\nlZ81a1Yq//GPfzyV/53f+Z1U/s4770zlb7vttlQeNjTe/3YFAAAAAACwEQYgAAAAAABAcwxAAAAA\nAACA5hiAAAAAAAAAzTEAAQAAAAAAmmMAAgAAAAAANMcABAAAAAAAaI4BCAAAAAAA0BwDEAAAAAAA\noDkGIAAAAAAAQHMMQAAAAAAAgObMHPYCAIDxd8EFF6TyP/nJTzpaCV26+OKLU/lTTjkllb/99ttT\neYBRd+SRR6by2evmqHn66aeHvQSgh17/+ten8t/97ndT+T333DOVn4p169al8itWrOhmIRP23Xff\nVP4P//APU/laayp/2223pfIREd/85jdT+SuuuCKVf/LJJ1N5hscdIAAAAAAAQHMMQAAAAAAAgOYY\ngAAAAAAAAM0xAAEAAAAAAJpjAAIAAAAAADTHAAQAAAAAAGiOAQgAAAAAANAcAxAAAAAAAKA5BiAA\nAAAAAEBzDEAAAAAAAIDmGIAAAAAAAADNmTnsBQAA3fvYxz7W6fNfeeWVnT4/o2HVqlWp/M0335zK\n77///qk8wHT75Cc/mcqfe+65qfzs2bNT+aVLl6byH/7wh1P5rI985CPpY6666qoOVgL0yWGHHZbK\n77nnnqn8unXrUvlrr702lY+IOPXUU1P5FStWpM+Rke2jt73tban8QQcdlMovWbIklY+IOPvss1P5\nE044IZU/9thjU/mrr746lWdw3AECAAAAAAA0xwAEAAAAAABojgEIAAAAAADQHAMQAAAAAACgOQYg\nAAAAAABAcwxAAAAAAACA5hiAAAAAAAAAzTEAAQAAAAAAmmMAAgAAAAAANMcABAAAAAAAaI4BCAAA\nAAAA0JyZw14AANC9nXbaadhLoAG/+MUvUvknn3wylT/00ENT+Xe+852p/H333ZfKA23bZ5990sec\nfPLJqfzMmbm33EuWLEnlzz777FT+5z//eSqftf3223f6/AAbc+WVV6byDzzwQCq/evXqVH758uWp\n/Ch67rnnUvnsv2dn85dffnkqHxHxvve9L5W/6KKLUvlLL700lb/33ntT+YcffjiVZ9PcAQIAAAAA\nADTHAAQAAAAAAGjOZgcgpZSLSymrSyn3bfDY50opK0spd0/89cFulwlAa/QLAIOmWwDogn4BGF+T\nuQPkkoj4wEYeP7vWutfEX/9zsMsCoAcuCf0CwGBdEroFgMG7JPQLwFja7ACk1npLRDw1DWsBoEf0\nCwCDplsA6IJ+ARhfW/IdIJ8qpfzbxG2Ar9tUqJRydCnlzlLKnVtwLgD6Q78AMGi6BYAu6BeAETfV\nAch5EfGWiNgrIp6IiDM3Fay1XlBrnVdrnTfFcwHQH/oFgEHTLQB0Qb8AjIEpDUBqratqrS/WWl+K\niAsjYr/BLguAPtIvAAyabgGgC/oFYDxMaQBSStlxg99+OCLuG8xyAOgz/QLAoOkWALqgXwDGw8zN\nBUop/xARB0bEb5ZSHo+IUyPiwFLKXhFRI2JFRCzucI0ANEi/ADBougWALugXgPG12QFIrXXRRh6+\nqIO1ANAj+gWAQdMtAHRBvwCMr80OQAAAYDrMmTMnlf/MZz6Tyh955JGpPNC2G2+8MX3M61//+lT+\nL//yL1P5M844I5V/zWtyn2r97W9/O5VfuHBhKg8wDP/5n/+Zyt92220drYSu/PSnP00fs3Tp0lT+\nxRdf7PT5s5368MMPp/Js2pS+AwQAAAAAAGCUGYAAAAAAAADNMQABAAAAAACaYwACAAAAAAA0xwAE\nAAAAAABojgEIAAAAAADQHAMQAAAAAACgOQYgAAAAAABAcwxAAAAAAACA5hiAAAAAAAAAzTEAAQAA\nAAAAmjNz2AsAAICpmDNnzrCXAHRo1qxZqfwZZ5yRym+33XapfETEF77whVT+i1/8YvocGS+99FIq\nf/3116fyCxcuTOUBYFxdd911qfyjjz6ayr/hDW9I5Rkcd4AAAAAAAADNMQABAAAAAACaYwACAAAA\nAAA0xwAEAAAAAABojgEIAAAAAADQHAMQAAAAAACgOQYgAAAAAABAcwxAAAAAAACA5hiAAAAAAAAA\nzTEAAQAAAAAAmmMAAgAAAAAANMcABAAAAAAAaM7MYS8AAOjeunXrOn3+bbbZptPnB6B/3vSmN6Xy\nxx13XCp/1113pfIREeeee24q/9JLL6XP0aWp7BkA+uDNb35zKr/99tt3tBIGzR0gAAAAAABAcwxA\nAAAAAACA5hiAAAAAAAAAzTEAAQAAAAAAmmMAAgAAAAAANMcABAAAAAAAaI4BCAAAAAAA0BwDEAAA\nAAAAoDkGIAAAAAAAQHMMQAAAAAAAgOYYgAAAAAAAAM2ZOewFAADdO//881P5I444IpW/7LLLUvkF\nCxak8g8++GAqTz+sWrVq2EsAOrR48eJOn/+UU05JH7N69eoOVjJ95s2bN+wlAAzd/PnzU/kvfvGL\nqfy+++6byjMaTjrppFR+22237WglDJo7QAAAAAAAgOYYgAAAAAAAAM0xAAEAAAAAAJpjAAIAAAAA\nADTHAAQAAAAAAGiOAQgAAAAAANAcAxAAAAAAAKA5BiAAAAAAAEBzDEAAAAAAAIDmGIAAAAAAAADN\nMQABAAAAAACaM3PYCwAAurd27dpU/p577knl99xzz1T+hhtuSOXnz5+fykdEPPTQQ+ljeHW//uu/\nnsrPnTs3lX/66adT+XPPPTeVB4brwAMPTOWPO+64bhYy4Y477uj0+afDrrvumsqfeOKJ3SwEYIws\nXrw4lX/hhRc6Wgld+tKXvpTKH3XUUan8I488kspfeOGFqTyD4w4QAAAAAACgOZsdgJRSdi6l/Gsp\n5YFSyv2llE9PPL5dKeWmUsoPJ359XffLBaAV+gWAQdMtAHRBvwCMr8ncAfJCRBxfa/1vEfHfI+KY\nUsoeEXFSRNxca90tIm6e+D0ATJZ+AWDQdAsAXdAvAGNqswOQWusTtda7Jn5eFxEPRMROEfGhiPj6\nROzrEXFYV4sEoD36BYBB0y0AdEG/AIyv1HeAlFJ2jYi9I+L2iNih1vpExPoiiIjct1wCwAT9AsCg\n6RYAuqBfAMbLzMkGSym/ERFXR8Rxtda1pZTJHnd0RBw9teUB0Dr9AsCg6RYAuqBfAMbPpO4AKaXM\nivUX+CtqrddMPLyqlLLjxJ/vGBGrN3ZsrfWCWuu8Wuu8QSwYgHboFwAGTbcA0AX9AjCeNjsAKevH\n2RdFxAO11rM2+KPrIuKIiZ+PiIhvDX55ALRKvwAwaLoFgC7oF4DxNZmPwHpPRPxxRNxbSrl74rGT\nI+L0iPjHUsonIuJHEfF73SwRgEbpFwAGTbcA0AX9AjCmNjsAqbX+r4jY1IcaHjTY5QDQF/oFgEHT\nLQB0Qb8AjK9JfQcIAAAAAADAOJnMR2DBSPnsZz+byh988MEdrQRgfDz44IOp/Pvf//5U/rLLLkvl\nFy5cmMp/5zvfSeUjIo4//vhUfu3atan8VNbUpd133z2V33vvvdPnOPHEE1P5d73rXan8+eefn8o/\n9NBDqTwwXDvttFMqP2PGjI5Wst6cOXPSx2y99dap/OzZs1P5j3/846n84sWLU/k3velNqfwPfvCD\nVP7yyy9P5QGG4e/+7u9S+W9/+9up/NKlS1P5iIgzzzwzlc/+e/CaNWtS+aztt98+lZ8/f34qf/jh\nh6fyERHvec97Uvl169al8n/xF3+Ryi9fvjyVZ3DcAQIAAAAAADTHAAQAAAAAAGiOAQgAAAAAANAc\nAxAAAAAAAKA5BiAAAAAAAEBzDEAAAAAAAIDmGIAAAAAAAADNMQABAAAAAACaYwACAAAAAAA0xwAE\nAAAAAABojgEIAAAAAADQnFJrnb6TlTJ9J6NZW221VSr/s5/9rKOVTM1tt92Wyh966KHpczz99NPp\nYxg7y2qt84a9iFGhX4Zvm222SeW/8Y1vpPLz589P5afi+eefT+Ufe+yxjlYyNa997WtT+e22266j\nlfzSVVddlcr/6Z/+aSr/7LPPpvJsXq21DHsNo0K3DN+jjz6ayu+6667dLGSEZd/PX3/99an8Jz7x\niVT+pz/9aSpPb3jvsgH9MnyzZ89O5U855ZRU/s///M9T+Yj8f+v6j//4j1T+nnvuSeWz9tprr1R+\n22237Wglv3T55Zen8kuWLEnlV65cmcozeJN97+IOEAAAAAAAoDkGIAAAAAAAQHMMQAAAAAAAgOYY\ngAAAAAAAAM0xAAEAAAAAAJpjAAIAAAAAADTHAAQAAAAAAGiOAQgAAAAAANAcAxAAAAAAAKA5BiAA\nAAAAAEBzDEAAAAAAAIDmlFrr9J2slOk7Gc2aMWNGKr9w4cJU/vjjj0/l//Zv/zaVX7ZsWSq/YsWK\nVJ7eWFZrnTfsRYwK/TJ+fu3Xfi2V32abbdLnyF7Ps33xjne8I5UfNd///vfTx/zVX/1VKn/rrbem\n8s8991wqz+DVWsuw1zAqdMvwvf3tb0/ljz322FT+yCOPTOUjIrbaaqtUPvt++7vf/W4q/4UvfCGV\nv+WWW1J5GBDvXTagX9r3W7/1W+ljzjjjjA5W8kuHHXZYKr/11lun8g8//HAqf8cdd6Ty3/jGN1L5\niIh//ud/TuVffPHF9DkYrsm+d3EHCAAAAAAA0BwDEAAAAAAAoDkGIAAAAAAAQHMMQAAAAAAAgOYY\ngAAAAAAAAM0xAAEAAAAAAJpjAAIAAAAAADTHAAQAAAAAAGiOAQgAAAAAANAcAxAAAAAAAKA5BiAA\nAAAAAEBzSq11+k5WyvSdDKBty2qt84a9iFGhXwAGo9Zahr2GUaFbAAbGe5cN6BeAwZjsexd3gAAA\nAAAAAM0xAAEAAAAAAJpjAAIAAAAAADTHAAQAAAAAAGiOAQgAAAAAANAcAxAAAAAAAKA5BiAAAAAA\nAEBzDEAAAAAAAIDmGIAAAAAAAADNMQABAAAAAACaYwACAAAAAAA0xwAEAAAAAABojgEIAAAAAADQ\nHAMQAAAAAACgOZsdgJRSdi6l/Gsp5YFSyv2llE9PPP65UsrKUsrdE399sPvlAtAK/QLAoOkWALqg\nXwDGV6m1vnqglB0jYsda612llG0iYllEHBYRvx8RP6u1/s2kT1bKq58MgMlaVmudN+xFbAn9AjB6\naq1l2GvYEroFYCR57/Krz6VfAAZgsu9dZk7iiZ6IiCcmfl5XSnkgInbasuUB0Hf6BYBB0y0AdEG/\nAIyv1HeAlFJ2jYi9I+L2iYc+VUr5t1LKxaWU123imKNLKXeWUu7copUC0Cz9AsCg6RYAuqBfAMbL\nZj8C6/8HS/mNiPheRJxWa72mlLJDRDwZETUi/kesvxXw45t5Drf5AQzG2N9G/jL9AjA6xv0jsF6m\nWwBGivcuv/oc+gVgACb73mVSd4CUUmZFxNURcUWt9ZqJE6yqtb5Ya30pIi6MiP2mulgA+km/ADBo\nugWALugXgPG02QFIKaVExEUR8UCt9awNHt9xg9iHI+K+wS8PgFbpFwAGTbcA0AX9AjC+Nvsl6BHx\nnoj444i4t5Ry98RjJ0fEolLKXrH+Nr8VEbG4kxUC0Cr9AsCg6RYAuqBfAMbUpL8DZCAn8zmHAIPS\nzOfoDoJ+ARiMVr4DZBB0C8DAeO+yAf0CMBgD/Q4QAAAAAACAcWIAAgAAAAAANMcABAAAAAAAaI4B\nCAAAAAAA0BwDEAAAAAAAoDkGIAAAAAAAQHMMQAAAAAAAgOYYgAAAAAAAAM0xAAEAAAAAAJpjAAIA\nAAAAADTHAAQAAAAAAGiOAQjhj24QAAAGpklEQVQAAAAAANAcAxAAAAAAAKA5BiAAAAAAAEBzDEAA\nAAAAAIDmGIAAAAAAAADNMQABAAAAAACaYwACAAAAAAA0xwAEAAAAAABojgEIAAAAAADQHAMQAAAA\nAACgOQYgAAAAAABAcwxAAAAAAACA5hiAAAAAAAAAzTEAAQAAAAAAmjNzms/3ZET83408/psTf9Yn\nfdtz3/YbYc99MMz9vmlI5x1V+mW9vu03wp77oG/7jRjennXLr9Itv9S3PfdtvxH23Afeu4wO/bJe\n3/YbYc990Lf9RozBe5dSa+1yIZNbRCl31lrnDXsd06lve+7bfiPsuQ/6tt9x1LfXqG/7jbDnPujb\nfiP6uedx0sfXp2977tt+I+y5D/q233HUt9eob/uNsOc+6Nt+I8Zjzz4CCwAAAAAAaI4BCAAAAAAA\n0JxRGYBcMOwFDEHf9ty3/UbYcx/0bb/jqG+vUd/2G2HPfdC3/Ub0c8/jpI+vT9/23Lf9RthzH/Rt\nv+Oob69R3/YbYc990Lf9RozBnkfiO0AAAAAAAAAGaVTuAAEAAAAAABiYoQ9ASikfKKU8VEpZXko5\nadjr6VopZUUp5d5Syt2llDuHvZ4ulFIuLqWsLqXct8Fj25VSbiql/HDi19cNc42Dtok9f66UsnLi\ntb67lPLBYa5xkEopO5dS/rWU8kAp5f5SyqcnHm/2dX6VPTf7Oo+zvnVLhH5p9LrTq26J6F+/6Jbx\n07d+0S1tXXNe1rd+6Vu3ROiXcdO3bonQL41ed3rVLRH965dx7pahfgRWKWVGRDwcEQdHxOMRcUdE\nLKq1/p+hLapjpZQVETGv1vrksNfSlVLK+yLiZxFxaa31nROPfTkinqq1nj5R6K+rtZ44zHUO0ib2\n/LmI+Fmt9W+GubYulFJ2jIgda613lVK2iYhlEXFYRBwZjb7Or7Ln349GX+dx1cduidAvjV53etUt\nEf3rF90yXvrYL7qlrWvOy/rWL33rlgj9Mk762C0R+qXR606vuiWif/0yzt0y7DtA9ouI5bXWR2ut\nz0XEVRHxoSGviS1Ua70lIp56xcMfioivT/z89Vj/D0gzNrHnZtVan6i13jXx87qIeCAidoqGX+dX\n2TOjR7c0qm/90rduiehfv+iWsaNfGtS3bonoX7/0rVsi9MuY0S2N6lu/9K1bIvrXL+PcLcMegOwU\nEY9t8PvHY0z+xm2BGhHfKaUsK6UcPezFTKMdaq1PRKz/ByYi5g55PdPlU6WUf5u4FbCJW95eqZSy\na0TsHRG3R09e51fsOaIHr/OY6WO3ROiXpq87r9CLa07f+kW3jIU+9otuafSaswnNX3f61i0R+mUM\n9LFbIvRL09edV+jFNadv/TJu3TLsAUjZyGPD+0yu6fGeWus+EbEgIo6ZuEWMNp0XEW+JiL0i4omI\nOHO4yxm8UspvRMTVEXFcrXXtsNczHTay5+Zf5zHUx26J0C990YtrTt/6RbeMjT72i27pj+avO33r\nlgj9Mib62C0R+qUvenHN6Vu/jGO3DHsA8nhE7LzB798YET8e0lqmRa31xxO/ro6IpbH+dsc+WDXx\nWXEvf2bc6iGvp3O11lW11hdrrS9FxIXR2GtdSpkV6y94V9Rar5l4uOnXeWN7bv11HlO965YI/RLR\n5nXnlfpwzelbv+iWsdK7ftEt7V1zNqX1607fuiVCv4yR3nVLhH6JaPO680p9uOb0rV/GtVuGPQC5\nIyJ2K6X8dilldkR8NCKuG/KaOlNK2XriS2KilLJ1RBwSEfcNd1XT5rqIOGLi5yMi4ltDXMu0ePli\nN+HD0dBrXUopEXFRRDxQaz1rgz9q9nXe1J5bfp3HWK+6JUK/RKPXnY1p/ZrTt37RLWOnV/2iW9q7\n5ryalq87feuWCP0yZnrVLRH6JRq97mxM69ecvvXLOHdLqXW4d9aVUj4YEedExIyIuLjWetpQF9Sh\nUsqbY/1kOyJiZkRc2eJ+Syn/EBEHRsRvRsSqiDg1Iq6NiH+MiF0i4kcR8Xu11ma+HGkTez4w1t/+\nVSNiRUQsfvkzAMddKeW9EfH9iLg3Il6aePjkWP/Zf02+zq+y50XR6Os8zvrULRH6Jdq97vSqWyL6\n1y+6Zfz0qV90S3vXnJf1rV/61i0R+mXc9KlbIvRLtHvd6VW3RPSvX8a5W4Y+AAEAAAAAABi0YX8E\nFgAAAAAAwMAZgAAAAAAAAM0xAAEAAAAAAJpjAAIAAAAAADTHAAQAAAAAAGiOAQgAAAAAANAcAxAA\nAAAAAKA5BiAAAAAAAEBz/h8lN7yfXYry7gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 2016x2016 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = get_dataflow(4, 'train')\n",
    "df.reset_state()\n",
    "\n",
    "fig =plt.figure(figsize=(28, 28))\n",
    "\n",
    "for idx, dp in enumerate(df.get_data()):\n",
    "    if idx == 0:\n",
    "        for i in range(4):\n",
    "            img = dp[idx][i]\n",
    "            fig.add_subplot(1, 4, i + 1)\n",
    "            plt.imshow(img, cmap='gray')\n",
    "        plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model \n",
    "#### Model includes Loss function & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Description of ModelDesc at\n",
    "# https://tensorpack.readthedocs.io/modules/graph_builder.html#tensorpack.graph_builder.ModelDesc\n",
    "class Model(ModelDesc):\n",
    "    def inputs(self):\n",
    "        \"\"\"\n",
    "        Define input shape\n",
    "        \"\"\"\n",
    "        return [tf.placeholder(tf.float32, [None, 28, 28], 'input'),\n",
    "                tf.placeholder(tf.int32, [None], 'label')]\n",
    "\n",
    "    def build_graph(self, image, label):\n",
    "        \"\"\"\n",
    "        Build the model which takes the input and return cost. \n",
    "        \"\"\"\n",
    "        # NHW to NHWC\n",
    "        image = tf.expand_dims(image, 3)\n",
    "\n",
    "        with argscope(Conv2D, filters=32, kernel_size=3, activation=tf.nn.relu):\n",
    "            with tf.name_scope('layer1') as scope:\n",
    "                layer1 = (LinearWrap(image)\n",
    "                          .Conv2D('conv0')\n",
    "                          .MaxPooling('pool0', 2)\n",
    "                          .Dropout('dropout', rate=0.7)())\n",
    "\n",
    "        with argscope(Conv2D, filters=64, kernel_size=3, activation=tf.nn.relu):\n",
    "            with tf.name_scope('layer2') as scope:\n",
    "                layer2 = (LinearWrap(layer1)\n",
    "                          .Conv2D('conv1')\n",
    "                          .MaxPooling('pool1', 2)\n",
    "                          .Dropout('dropout', rate=0.7)())\n",
    "\n",
    "        with argscope(Conv2D, filters=128, kernel_size=3, activation=tf.nn.relu):\n",
    "            with tf.name_scope('layer3') as scope:\n",
    "                layer3 = (LinearWrap(layer2)\n",
    "                          .Conv2D('conv2')\n",
    "                          .MaxPooling('pool2', 2)\n",
    "                          .Dropout('dropout', rate=0.7)\n",
    "                          .FullyConnected('fc1', units=10,\n",
    "                                          activation=tf.identity)())\n",
    "                \n",
    "        # Cost function\n",
    "        cost = tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(logits=layer3, \n",
    "                                                           labels=label),\n",
    "            name='Loss')\n",
    "        \n",
    "        correct = tf.cast(tf.equal(tf.argmax(layer3, -1, \n",
    "                                             output_type=tf.int32), \n",
    "                                   label),\n",
    "                          tf.float32)\n",
    "        accuracy = tf.reduce_mean(correct, name='accuracy')\n",
    "        train_error = tf.reduce_mean(1 - correct, name='train_error')\n",
    "        \n",
    "        summary.add_moving_summary(train_error, accuracy)\n",
    "        return cost\n",
    "\n",
    "    def optimizer(self):\n",
    "        lr = tf.train.exponential_decay(\n",
    "            learning_rate=0.001,\n",
    "            global_step=get_global_step_var(),\n",
    "            decay_steps=468 * 10,\n",
    "            decay_rate=0.3, staircase=True, name='learning_rate')\n",
    "        # for tensorboard.\n",
    "        tf.summary.scalar('lr', lr)\n",
    "        return tf.train.AdamOptimizer(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. main.py\n",
    "#### `logger` for tensorboard, `TrainConfig` for model configuration including model saver.\n",
    "* If you use **auto_set_dir()**, it makes a **`'train_log'`** directory and makes another directory in it \n",
    "   with the same name of file.py. You can see the scalars with tensorboard at there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard and datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:37:53 @logger.py:109]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Log directory ./mnist_result exists! Use 'd' to delete it. \n",
      "\u001b[32m[0814 17:37:53 @logger.py:112]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m If you're resuming from a previous run, you can choose to keep it.\n",
      "Press any other key to exit. \n",
      "Select Action: k (keep) / d (delete) / q (quit):k\n",
      "\u001b[32m[0814 17:37:57 @logger.py:67]\u001b[0m Existing log file './mnist_result/log.log' backuped to './mnist_result/log.log.0814-173757'\n",
      "\u001b[32m[0814 17:37:57 @logger.py:74]\u001b[0m Argv: /anaconda/lib/python3.6/site-packages/ipykernel_launcher.py -f /Users/chayesol/Library/Jupyter/runtime/kernel-e7081d95-93f3-403d-b842-642e49b327fb.json\n"
     ]
    }
   ],
   "source": [
    "# for tensorboard \n",
    "logger.set_logger_dir('./mnist_result')\n",
    "# logger.auto_set_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataflow\n",
    "df = get_dataflow(100, 'train')\n",
    "df_test = get_dataflow(100, 'test')\n",
    "\n",
    "df.reset_state()\n",
    "df_test.reset_state()\n",
    "steps_per_epoch = df.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:06:21 @input_source.py:205]\u001b[0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...\n",
      "\u001b[32m[0814 17:06:21 @trainers.py:51]\u001b[0m Building graph for a single training tower ...\n",
      "\u001b[32m[0814 17:06:21 @registry.py:121]\u001b[0m conv0 input: [None, 28, 28, 1]\n",
      "\u001b[32m[0814 17:06:21 @registry.py:129]\u001b[0m conv0 output: [None, 28, 28, 32]\n",
      "\u001b[32m[0814 17:06:21 @registry.py:121]\u001b[0m pool0 input: [None, 28, 28, 32]\n",
      "\u001b[32m[0814 17:06:21 @registry.py:129]\u001b[0m pool0 output: [None, 14, 14, 32]\n",
      "\u001b[32m[0814 17:06:21 @registry.py:121]\u001b[0m conv1 input: [None, 14, 14, 32]\n",
      "\u001b[32m[0814 17:06:21 @registry.py:129]\u001b[0m conv1 output: [None, 14, 14, 64]\n",
      "\u001b[32m[0814 17:06:21 @registry.py:121]\u001b[0m pool1 input: [None, 14, 14, 64]\n",
      "\u001b[32m[0814 17:06:21 @registry.py:129]\u001b[0m pool1 output: [None, 7, 7, 64]\n",
      "\u001b[32m[0814 17:06:21 @registry.py:121]\u001b[0m conv2 input: [None, 7, 7, 64]\n",
      "\u001b[32m[0814 17:06:21 @registry.py:129]\u001b[0m conv2 output: [None, 7, 7, 128]\n",
      "\u001b[32m[0814 17:06:21 @registry.py:121]\u001b[0m pool2 input: [None, 7, 7, 128]\n",
      "\u001b[32m[0814 17:06:21 @registry.py:129]\u001b[0m pool2 output: [None, 3, 3, 128]\n",
      "\u001b[32m[0814 17:06:21 @registry.py:121]\u001b[0m fc1 input: [None, 3, 3, 128]\n",
      "\u001b[32m[0814 17:06:21 @registry.py:129]\u001b[0m fc1 output: [None, 10]\n",
      "\u001b[32m[0814 17:06:21 @model_utils.py:64]\u001b[0m \u001b[36mTrainable Variables: \n",
      "\u001b[0mname       shape              dim\n",
      "---------  ---------------  -----\n",
      "conv0/W:0  [3, 3, 1, 32]      288\n",
      "conv0/b:0  [32]                32\n",
      "conv1/W:0  [3, 3, 32, 64]   18432\n",
      "conv1/b:0  [64]                64\n",
      "conv2/W:0  [3, 3, 64, 128]  73728\n",
      "conv2/b:0  [128]              128\n",
      "fc1/W:0    [1152, 10]       11520\n",
      "fc1/b:0    [10]                10\u001b[36m\n",
      "Total #vars=8, #params=104202, size=0.40MB\u001b[0m\n",
      "\u001b[32m[0814 17:06:21 @base.py:187]\u001b[0m Setup callbacks graph ...\n",
      "\u001b[32m[0814 17:06:21 @inference_runner.py:146]\u001b[0m [InferenceRunner] Building tower 'InferenceTower' on device /gpu:0 ...\n",
      "\u001b[32m[0814 17:06:22 @summary.py:38]\u001b[0m Maintain moving average summary of 2 tensors in collection MOVING_SUMMARY_OPS.\n",
      "\u001b[32m[0814 17:06:22 @summary.py:75]\u001b[0m Summarizing collection 'summaries' of size 4.\n",
      "\u001b[32m[0814 17:06:22 @base.py:205]\u001b[0m Creating the session ...\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "\u001b[32m[0814 17:06:22 @base.py:211]\u001b[0m Initializing the session ...\n",
      "\u001b[32m[0814 17:06:22 @base.py:218]\u001b[0m Graph Finalized.\n",
      "\u001b[32m[0814 17:06:22 @concurrency.py:37]\u001b[0m Starting EnqueueThread QueueInput/input_queue ...\n",
      "\u001b[32m[0814 17:06:22 @inference_runner.py:101]\u001b[0m [InferenceRunner] Will eval 100 iterations\n",
      "\u001b[32m[0814 17:06:22 @base.py:250]\u001b[0m Start Epoch 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|600/600[01:14<00:00, 8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:07:37 @base.py:260]\u001b[0m Epoch 1 (global_step 600) finished, time:1 minute 14 seconds.\n",
      "\u001b[32m[0814 17:07:37 @saver.py:77]\u001b[0m Model saved to ./mnist_result/model-600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:03<00:00,25.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:07:40 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0814 17:07:40 @monitor.py:435]\u001b[0m accuracy: 0.62432\n",
      "\u001b[32m[0814 17:07:40 @monitor.py:435]\u001b[0m lr: 0.001\n",
      "\u001b[32m[0814 17:07:40 @monitor.py:435]\u001b[0m train_error: 0.37568\n",
      "\u001b[32m[0814 17:07:40 @monitor.py:435]\u001b[0m validation_Loss: 1.0275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:07:40 @monitor.py:435]\u001b[0m validation_accuracy: 0.8516\n",
      "\u001b[32m[0814 17:07:40 @group.py:48]\u001b[0m Callbacks took 3.878 sec in total. InferenceRunner: 3.85 seconds\n",
      "\u001b[32m[0814 17:07:40 @base.py:250]\u001b[0m Start Epoch 2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|600/600[01:10<00:00, 8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:08:51 @base.py:260]\u001b[0m Epoch 2 (global_step 1200) finished, time:1 minute 10 seconds.\n",
      "\u001b[32m[0814 17:08:51 @saver.py:77]\u001b[0m Model saved to ./mnist_result/model-1200.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:03<00:00,27.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:08:55 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0814 17:08:55 @monitor.py:435]\u001b[0m accuracy: 0.81819\n",
      "\u001b[32m[0814 17:08:55 @monitor.py:435]\u001b[0m lr: 0.001\n",
      "\u001b[32m[0814 17:08:55 @monitor.py:435]\u001b[0m train_error: 0.18181\n",
      "\u001b[32m[0814 17:08:55 @monitor.py:435]\u001b[0m validation_Loss: 0.40052\n",
      "\u001b[32m[0814 17:08:55 @monitor.py:435]\u001b[0m validation_accuracy: 0.9258\n",
      "\u001b[32m[0814 17:08:55 @group.py:48]\u001b[0m Callbacks took 3.693 sec in total. InferenceRunner: 3.67 seconds\n",
      "\u001b[32m[0814 17:08:55 @base.py:250]\u001b[0m Start Epoch 3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|600/600[01:07<00:00, 8.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:10:02 @base.py:260]\u001b[0m Epoch 3 (global_step 1800) finished, time:1 minute 7 seconds.\n",
      "\u001b[32m[0814 17:10:02 @saver.py:77]\u001b[0m Model saved to ./mnist_result/model-1800.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:03<00:00,26.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:10:06 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0814 17:10:06 @monitor.py:435]\u001b[0m accuracy: 0.87529\n",
      "\u001b[32m[0814 17:10:06 @monitor.py:435]\u001b[0m lr: 0.001\n",
      "\u001b[32m[0814 17:10:06 @monitor.py:435]\u001b[0m train_error: 0.12471\n",
      "\u001b[32m[0814 17:10:06 @monitor.py:435]\u001b[0m validation_Loss: 0.21716\n",
      "\u001b[32m[0814 17:10:06 @monitor.py:435]\u001b[0m validation_accuracy: 0.956\n",
      "\u001b[32m[0814 17:10:06 @group.py:48]\u001b[0m Callbacks took 3.823 sec in total. InferenceRunner: 3.8 seconds\n",
      "\u001b[32m[0814 17:10:06 @base.py:250]\u001b[0m Start Epoch 4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|600/600[01:17<00:00, 7.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:11:24 @base.py:260]\u001b[0m Epoch 4 (global_step 2400) finished, time:1 minute 17 seconds.\n",
      "\u001b[32m[0814 17:11:24 @saver.py:77]\u001b[0m Model saved to ./mnist_result/model-2400.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:03<00:00,25.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:11:28 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0814 17:11:28 @monitor.py:435]\u001b[0m accuracy: 0.89303\n",
      "\u001b[32m[0814 17:11:28 @monitor.py:435]\u001b[0m lr: 0.001\n",
      "\u001b[32m[0814 17:11:28 @monitor.py:435]\u001b[0m train_error: 0.10697\n",
      "\u001b[32m[0814 17:11:28 @monitor.py:435]\u001b[0m validation_Loss: 0.15336\n",
      "\u001b[32m[0814 17:11:28 @monitor.py:435]\u001b[0m validation_accuracy: 0.9672\n",
      "\u001b[32m[0814 17:11:28 @group.py:48]\u001b[0m Callbacks took 4.013 sec in total. InferenceRunner: 3.96 seconds\n",
      "\u001b[32m[0814 17:11:28 @base.py:250]\u001b[0m Start Epoch 5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|600/600[01:12<00:00, 7.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:12:41 @base.py:260]\u001b[0m Epoch 5 (global_step 3000) finished, time:1 minute 12 seconds.\n",
      "\u001b[32m[0814 17:12:41 @saver.py:77]\u001b[0m Model saved to ./mnist_result/model-3000.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:04<00:00,23.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:12:45 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0814 17:12:45 @monitor.py:435]\u001b[0m accuracy: 0.91788\n",
      "\u001b[32m[0814 17:12:45 @monitor.py:435]\u001b[0m lr: 0.001\n",
      "\u001b[32m[0814 17:12:45 @monitor.py:435]\u001b[0m train_error: 0.082119\n",
      "\u001b[32m[0814 17:12:45 @monitor.py:435]\u001b[0m validation_Loss: 0.12471\n",
      "\u001b[32m[0814 17:12:45 @monitor.py:435]\u001b[0m validation_accuracy: 0.973\n",
      "\u001b[32m[0814 17:12:45 @group.py:48]\u001b[0m Callbacks took 4.292 sec in total. InferenceRunner: 4.27 seconds\n",
      "\u001b[32m[0814 17:12:45 @base.py:250]\u001b[0m Start Epoch 6 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|600/600[01:15<00:00, 7.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:14:00 @base.py:260]\u001b[0m Epoch 6 (global_step 3600) finished, time:1 minute 15 seconds.\n",
      "\u001b[32m[0814 17:14:00 @saver.py:77]\u001b[0m Model saved to ./mnist_result/model-3600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:04<00:00,23.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:14:05 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0814 17:14:05 @monitor.py:435]\u001b[0m accuracy: 0.92214\n",
      "\u001b[32m[0814 17:14:05 @monitor.py:435]\u001b[0m lr: 0.001\n",
      "\u001b[32m[0814 17:14:05 @monitor.py:435]\u001b[0m train_error: 0.077856\n",
      "\u001b[32m[0814 17:14:05 @monitor.py:435]\u001b[0m validation_Loss: 0.098244\n",
      "\u001b[32m[0814 17:14:05 @monitor.py:435]\u001b[0m validation_accuracy: 0.9776\n",
      "\u001b[32m[0814 17:14:05 @group.py:48]\u001b[0m Callbacks took 4.262 sec in total. InferenceRunner: 4.24 seconds\n",
      "\u001b[32m[0814 17:14:05 @base.py:250]\u001b[0m Start Epoch 7 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|600/600[01:12<00:00, 8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:15:17 @base.py:260]\u001b[0m Epoch 7 (global_step 4200) finished, time:1 minute 12 seconds.\n",
      "\u001b[32m[0814 17:15:17 @saver.py:77]\u001b[0m Model saved to ./mnist_result/model-4200.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:03<00:00,25.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:15:21 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0814 17:15:21 @monitor.py:435]\u001b[0m accuracy: 0.9213\n",
      "\u001b[32m[0814 17:15:21 @monitor.py:435]\u001b[0m lr: 0.001\n",
      "\u001b[32m[0814 17:15:21 @monitor.py:435]\u001b[0m train_error: 0.078695\n",
      "\u001b[32m[0814 17:15:21 @monitor.py:435]\u001b[0m validation_Loss: 0.09223\n",
      "\u001b[32m[0814 17:15:21 @monitor.py:435]\u001b[0m validation_accuracy: 0.9785\n",
      "\u001b[32m[0814 17:15:21 @group.py:48]\u001b[0m Callbacks took 3.956 sec in total. InferenceRunner: 3.94 seconds\n",
      "\u001b[32m[0814 17:15:21 @base.py:250]\u001b[0m Start Epoch 8 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|600/600[01:20<00:00, 7.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:16:41 @base.py:260]\u001b[0m Epoch 8 (global_step 4800) finished, time:1 minute 20 seconds.\n",
      "\u001b[32m[0814 17:16:41 @saver.py:77]\u001b[0m Model saved to ./mnist_result/model-4800.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:04<00:00,24.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:16:45 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0814 17:16:45 @monitor.py:435]\u001b[0m accuracy: 0.93926\n",
      "\u001b[32m[0814 17:16:45 @monitor.py:435]\u001b[0m lr: 0.0003\n",
      "\u001b[32m[0814 17:16:45 @monitor.py:435]\u001b[0m train_error: 0.060739\n",
      "\u001b[32m[0814 17:16:45 @monitor.py:435]\u001b[0m validation_Loss: 0.071405\n",
      "\u001b[32m[0814 17:16:45 @monitor.py:435]\u001b[0m validation_accuracy: 0.9831\n",
      "\u001b[32m[0814 17:16:45 @group.py:48]\u001b[0m Callbacks took 4.053 sec in total. InferenceRunner: 4.03 seconds\n",
      "\u001b[32m[0814 17:16:45 @base.py:250]\u001b[0m Start Epoch 9 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|600/600[01:10<00:00, 7.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:17:56 @base.py:260]\u001b[0m Epoch 9 (global_step 5400) finished, time:1 minute 10 seconds.\n",
      "\u001b[32m[0814 17:17:56 @saver.py:77]\u001b[0m Model saved to ./mnist_result/model-5400.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:04<00:00,24.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:18:00 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0814 17:18:00 @monitor.py:435]\u001b[0m accuracy: 0.93876\n",
      "\u001b[32m[0814 17:18:00 @monitor.py:435]\u001b[0m lr: 0.0003\n",
      "\u001b[32m[0814 17:18:00 @monitor.py:435]\u001b[0m train_error: 0.061243\n",
      "\u001b[32m[0814 17:18:00 @monitor.py:435]\u001b[0m validation_Loss: 0.068353\n",
      "\u001b[32m[0814 17:18:00 @monitor.py:435]\u001b[0m validation_accuracy: 0.9839\n",
      "\u001b[32m[0814 17:18:00 @group.py:48]\u001b[0m Callbacks took 4.159 sec in total. InferenceRunner: 4.14 seconds\n",
      "\u001b[32m[0814 17:18:00 @base.py:250]\u001b[0m Start Epoch 10 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|600/600[01:07<00:00, 8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:19:07 @base.py:260]\u001b[0m Epoch 10 (global_step 6000) finished, time:1 minute 7 seconds.\n",
      "\u001b[32m[0814 17:19:07 @saver.py:77]\u001b[0m Model saved to ./mnist_result/model-6000.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:03<00:00,27.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:19:11 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0814 17:19:11 @monitor.py:435]\u001b[0m accuracy: 0.94222\n",
      "\u001b[32m[0814 17:19:11 @monitor.py:435]\u001b[0m lr: 0.0003\n",
      "\u001b[32m[0814 17:19:11 @monitor.py:435]\u001b[0m train_error: 0.057784\n",
      "\u001b[32m[0814 17:19:11 @monitor.py:435]\u001b[0m validation_Loss: 0.063313\n",
      "\u001b[32m[0814 17:19:11 @monitor.py:435]\u001b[0m validation_accuracy: 0.9847\n",
      "\u001b[32m[0814 17:19:11 @group.py:48]\u001b[0m Callbacks took 3.655 sec in total. InferenceRunner: 3.64 seconds\n",
      "\u001b[32m[0814 17:19:11 @base.py:264]\u001b[0m Training has finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:19:11 @input_source.py:160]\u001b[0m EnqueueThread QueueInput/input_queue Exited.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Configuration containing everything necessary in a training.\n",
    "\"\"\"\n",
    "config = TrainConfig(\n",
    "    model = Model(),\n",
    "    data = QueueInput(df),\n",
    "    callbacks = [\n",
    "        # save the model after every epoch\n",
    "        ModelSaver(checkpoint_dir='./mnist_result'),\n",
    "        InferenceRunner(\n",
    "            df_test,\n",
    "            ScalarStats(['Loss', 'accuracy'])),\n",
    "#         ScheduledHyperParamSetter('learning_rate',\n",
    "#                                   [(1, 0.1), \n",
    "#                                    (300, 0.01), \n",
    "#                                    (500, 0.001)])\n",
    "    ],\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    max_epoch = 10,\n",
    ")\n",
    "\n",
    "# training with CPU or GPU?\n",
    "if tf.test.gpu_device_name():\n",
    "    launch_train_with_config(config, SyncMultiGPUTrainer(4))\n",
    "else:\n",
    "    launch_train_with_config(config, SimpleTrainer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. Loading The Saved Model \n",
    "#### Loading saved model and learning 5 epochs more.\n",
    "##### In tensorflow, \n",
    "* **`.meta`** file means **the structure** of model, \n",
    "    all **variables, and operations.** \n",
    "* **`index`** means a binary file contating **weights, biases, and gradients**.\n",
    "\n",
    "* We are going to use **`PredictConfig`** to evaluate the loaded and more trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Transfer Learning\n",
    "* If you have any trouble with it, then consider **`logger.set_logger_dir(path_to_saved_model)`** carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:38:06 @varmanip.py:182]\u001b[0m Checkpoint path ./mnist_result/model-6000.index is auto-corrected to ./mnist_result/model-6000.\n",
      "\u001b[32m[0814 17:38:06 @config.py:215]\u001b[0m Found checkpoint at ./mnist_result/model-6000. session_init arguments will be overwritten.\n",
      "\u001b[32m[0814 17:38:06 @config.py:225]\u001b[0m Found history statistics from JSON. Overwrite the starting epoch to epoch #11.\n",
      "\u001b[32m[0814 17:38:06 @input_source.py:205]\u001b[0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...\n",
      "\u001b[32m[0814 17:38:06 @trainers.py:51]\u001b[0m Building graph for a single training tower ...\n",
      "\u001b[32m[0814 17:38:06 @registry.py:121]\u001b[0m conv0 input: [None, 28, 28, 1]\n",
      "\u001b[32m[0814 17:38:06 @registry.py:129]\u001b[0m conv0 output: [None, 28, 28, 32]\n",
      "\u001b[32m[0814 17:38:06 @registry.py:121]\u001b[0m pool0 input: [None, 28, 28, 32]\n",
      "\u001b[32m[0814 17:38:06 @registry.py:129]\u001b[0m pool0 output: [None, 14, 14, 32]\n",
      "\u001b[32m[0814 17:38:06 @registry.py:121]\u001b[0m conv1 input: [None, 14, 14, 32]\n",
      "\u001b[32m[0814 17:38:06 @registry.py:129]\u001b[0m conv1 output: [None, 14, 14, 64]\n",
      "\u001b[32m[0814 17:38:06 @registry.py:121]\u001b[0m pool1 input: [None, 14, 14, 64]\n",
      "\u001b[32m[0814 17:38:06 @registry.py:129]\u001b[0m pool1 output: [None, 7, 7, 64]\n",
      "\u001b[32m[0814 17:38:06 @registry.py:121]\u001b[0m conv2 input: [None, 7, 7, 64]\n",
      "\u001b[32m[0814 17:38:06 @registry.py:129]\u001b[0m conv2 output: [None, 7, 7, 128]\n",
      "\u001b[32m[0814 17:38:06 @registry.py:121]\u001b[0m pool2 input: [None, 7, 7, 128]\n",
      "\u001b[32m[0814 17:38:06 @registry.py:129]\u001b[0m pool2 output: [None, 3, 3, 128]\n",
      "\u001b[32m[0814 17:38:06 @registry.py:121]\u001b[0m fc1 input: [None, 3, 3, 128]\n",
      "\u001b[32m[0814 17:38:06 @registry.py:129]\u001b[0m fc1 output: [None, 10]\n",
      "\u001b[32m[0814 17:38:07 @model_utils.py:64]\u001b[0m \u001b[36mTrainable Variables: \n",
      "\u001b[0mname       shape              dim\n",
      "---------  ---------------  -----\n",
      "conv0/W:0  [3, 3, 1, 32]      288\n",
      "conv0/b:0  [32]                32\n",
      "conv1/W:0  [3, 3, 32, 64]   18432\n",
      "conv1/b:0  [64]                64\n",
      "conv2/W:0  [3, 3, 64, 128]  73728\n",
      "conv2/b:0  [128]              128\n",
      "fc1/W:0    [1152, 10]       11520\n",
      "fc1/b:0    [10]                10\u001b[36m\n",
      "Total #vars=8, #params=104202, size=0.40MB\u001b[0m\n",
      "\u001b[32m[0814 17:38:07 @base.py:187]\u001b[0m Setup callbacks graph ...\n",
      "\u001b[32m[0814 17:38:07 @inference_runner.py:146]\u001b[0m [InferenceRunner] Building tower 'InferenceTower' on device /gpu:0 ...\n",
      "\u001b[32m[0814 17:38:07 @summary.py:38]\u001b[0m Maintain moving average summary of 2 tensors in collection MOVING_SUMMARY_OPS.\n",
      "\u001b[32m[0814 17:38:07 @summary.py:75]\u001b[0m Summarizing collection 'summaries' of size 4.\n",
      "\u001b[32m[0814 17:38:07 @base.py:205]\u001b[0m Creating the session ...\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "\u001b[32m[0814 17:38:07 @base.py:211]\u001b[0m Initializing the session ...\n",
      "\u001b[32m[0814 17:38:07 @sessinit.py:117]\u001b[0m Restoring checkpoint from ./mnist_result/model-6000 ...\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_result/model-6000\n",
      "\u001b[32m[0814 17:38:07 @base.py:218]\u001b[0m Graph Finalized.\n",
      "\u001b[32m[0814 17:38:07 @concurrency.py:37]\u001b[0m Starting EnqueueThread QueueInput/input_queue ...\n",
      "\u001b[32m[0814 17:38:07 @steps.py:126]\u001b[0m Start training with global_step=6000\n",
      "\u001b[32m[0814 17:38:07 @inference_runner.py:101]\u001b[0m [InferenceRunner] Will eval 100 iterations\n",
      "\u001b[32m[0814 17:38:07 @monitor.py:317]\u001b[0m Found existing JSON inside ./mnist_result, will append to it.\n",
      "\u001b[32m[0814 17:38:07 @base.py:250]\u001b[0m Start Epoch 11 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|600/600[01:26<00:00, 6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:39:34 @base.py:260]\u001b[0m Epoch 11 (global_step 6600) finished, time:1 minute 26 seconds.\n",
      "\u001b[32m[0814 17:39:34 @saver.py:77]\u001b[0m Model saved to ./transfer/model-6600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:05<00:00,18.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:39:39 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0814 17:39:39 @monitor.py:435]\u001b[0m accuracy: 0.94823\n",
      "\u001b[32m[0814 17:39:39 @monitor.py:435]\u001b[0m lr: 0.0003\n",
      "\u001b[32m[0814 17:39:39 @monitor.py:435]\u001b[0m train_error: 0.051774\n",
      "\u001b[32m[0814 17:39:39 @monitor.py:435]\u001b[0m validation_Loss: 0.061184\n",
      "\u001b[32m[0814 17:39:39 @monitor.py:435]\u001b[0m validation_accuracy: 0.9856\n",
      "\u001b[32m[0814 17:39:39 @group.py:48]\u001b[0m Callbacks took 5.574 sec in total. InferenceRunner: 5.55 seconds\n",
      "\u001b[32m[0814 17:39:39 @base.py:250]\u001b[0m Start Epoch 12 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|600/600[01:26<00:00, 7.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:41:05 @base.py:260]\u001b[0m Epoch 12 (global_step 7200) finished, time:1 minute 26 seconds.\n",
      "\u001b[32m[0814 17:41:05 @saver.py:77]\u001b[0m Model saved to ./transfer/model-7200.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:05<00:00,17.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:41:11 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0814 17:41:11 @monitor.py:435]\u001b[0m accuracy: 0.94186\n",
      "\u001b[32m[0814 17:41:11 @monitor.py:435]\u001b[0m lr: 0.0003\n",
      "\u001b[32m[0814 17:41:11 @monitor.py:435]\u001b[0m train_error: 0.058136\n",
      "\u001b[32m[0814 17:41:11 @monitor.py:435]\u001b[0m validation_Loss: 0.057191\n",
      "\u001b[32m[0814 17:41:11 @monitor.py:435]\u001b[0m validation_accuracy: 0.9856\n",
      "\u001b[32m[0814 17:41:11 @group.py:48]\u001b[0m Callbacks took 5.628 sec in total. InferenceRunner: 5.61 seconds\n",
      "\u001b[32m[0814 17:41:11 @base.py:250]\u001b[0m Start Epoch 13 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|600/600[01:26<00:00, 6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:42:38 @base.py:260]\u001b[0m Epoch 13 (global_step 7800) finished, time:1 minute 26 seconds.\n",
      "\u001b[32m[0814 17:42:38 @saver.py:77]\u001b[0m Model saved to ./transfer/model-7800.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:06<00:00,16.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:42:44 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0814 17:42:44 @monitor.py:435]\u001b[0m accuracy: 0.94769\n",
      "\u001b[32m[0814 17:42:44 @monitor.py:435]\u001b[0m lr: 0.0003\n",
      "\u001b[32m[0814 17:42:44 @monitor.py:435]\u001b[0m train_error: 0.052311\n",
      "\u001b[32m[0814 17:42:44 @monitor.py:435]\u001b[0m validation_Loss: 0.056378\n",
      "\u001b[32m[0814 17:42:44 @monitor.py:435]\u001b[0m validation_accuracy: 0.9857\n",
      "\u001b[32m[0814 17:42:44 @group.py:48]\u001b[0m Callbacks took 6.237 sec in total. InferenceRunner: 6.21 seconds\n",
      "\u001b[32m[0814 17:42:44 @base.py:250]\u001b[0m Start Epoch 14 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|600/600[01:26<00:00, 7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:44:10 @base.py:260]\u001b[0m Epoch 14 (global_step 8400) finished, time:1 minute 26 seconds.\n",
      "\u001b[32m[0814 17:44:10 @saver.py:77]\u001b[0m Model saved to ./transfer/model-8400.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:05<00:00,18.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:44:16 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0814 17:44:16 @monitor.py:435]\u001b[0m accuracy: 0.94692\n",
      "\u001b[32m[0814 17:44:16 @monitor.py:435]\u001b[0m lr: 0.0003\n",
      "\u001b[32m[0814 17:44:16 @monitor.py:435]\u001b[0m train_error: 0.053084\n",
      "\u001b[32m[0814 17:44:16 @monitor.py:435]\u001b[0m validation_Loss: 0.056021\n",
      "\u001b[32m[0814 17:44:16 @monitor.py:435]\u001b[0m validation_accuracy: 0.9871\n",
      "\u001b[32m[0814 17:44:16 @group.py:48]\u001b[0m Callbacks took 5.374 sec in total. InferenceRunner: 5.36 seconds\n",
      "\u001b[32m[0814 17:44:16 @base.py:250]\u001b[0m Start Epoch 15 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|600/600[01:24<00:00, 7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:45:41 @base.py:260]\u001b[0m Epoch 15 (global_step 9000) finished, time:1 minute 24 seconds.\n",
      "\u001b[32m[0814 17:45:41 @saver.py:77]\u001b[0m Model saved to ./transfer/model-9000.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|100/100[00:05<00:00,18.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:45:46 @monitor.py:435]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0814 17:45:46 @monitor.py:435]\u001b[0m accuracy: 0.95449\n",
      "\u001b[32m[0814 17:45:46 @monitor.py:435]\u001b[0m lr: 0.0003\n",
      "\u001b[32m[0814 17:45:46 @monitor.py:435]\u001b[0m train_error: 0.045515\n",
      "\u001b[32m[0814 17:45:46 @monitor.py:435]\u001b[0m validation_Loss: 0.052748\n",
      "\u001b[32m[0814 17:45:46 @monitor.py:435]\u001b[0m validation_accuracy: 0.9865\n",
      "\u001b[32m[0814 17:45:46 @group.py:48]\u001b[0m Callbacks took 5.291 sec in total. InferenceRunner: 5.27 seconds\n",
      "\u001b[32m[0814 17:45:46 @base.py:264]\u001b[0m Training has finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 17:45:46 @input_source.py:160]\u001b[0m EnqueueThread QueueInput/input_queue Exited.\n"
     ]
    }
   ],
   "source": [
    "config = AutoResumeTrainConfig(\n",
    "    model = Model(),\n",
    "    session_init = get_model_loader('./mnist_result/model-6000.index'),\n",
    "    data = QueueInput(df),\n",
    "    callbacks = [\n",
    "        # save the model after every epoch\n",
    "        ModelSaver(checkpoint_dir='./transfer'),\n",
    "        InferenceRunner(\n",
    "            df_test,\n",
    "            ScalarStats(['Loss', 'accuracy'])),\n",
    "#         ScheduledHyperParamSetter('learning_rate',\n",
    "#                                   [(1, 0.1), \n",
    "#                                    (300, 0.01), \n",
    "#                                    (500, 0.001)])\n",
    "    ],\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    max_epoch = 15,\n",
    ")\n",
    "\n",
    "launch_train_with_config(config, SimpleTrainer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0814 15:31:02 @varmanip.py:182]\u001b[0m Checkpoint path ./mnist_result/model-6000.index is auto-corrected to ./mnist_result/model-6000.\n",
      "\u001b[32m[0814 15:31:02 @sessinit.py:90]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The following variables are in the checkpoint, but not found in the graph: beta1_power:0, beta2_power:0, global_step:0\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "\u001b[32m[0814 15:31:02 @sessinit.py:117]\u001b[0m Restoring checkpoint from ./mnist_result/model-6000 ...\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_result/model-6000\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "session = get_model_loader('./mnist_result/model-6000.index')\n",
    "\n",
    "pred_config = PredictConfig(\n",
    "        model=model,\n",
    "        session_init=session,\n",
    "        input_names=['input', 'label'],\n",
    "        output_names=['accuracy', 'Loss']\n",
    "    )\n",
    "pred = SimpleDatasetPredictor(pred_config, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|100/100[00:04<00:00,20.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.985\n",
      "Loss: 0.067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0.0\n",
    "total_loss = 0.0\n",
    "\n",
    "for i, (acc, loss) in enumerate(pred.get_result()):\n",
    "    accuracy += acc \n",
    "    total_loss += loss\n",
    "    \n",
    "print(\"Accuracy: {:0.3f}\".format(accuracy/(i+1)))\n",
    "print(\"Loss: {:0.3f}\".format(total_loss/(i+1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
